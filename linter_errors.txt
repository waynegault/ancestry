E111 Indentation is not a multiple of 4
   --> ai_api_test.py:512:1
    |
510 |         # Note: The new SDK uses 'http_options' for base_url if needed, or just api_key
511 |         if base_url:
512 |              client = genai.Client(api_key=api_key, http_options={'api_endpoint': base_url})
    | ^^^^^^^^^^^^^
513 |         else:
514 |              client = genai.Client(api_key=api_key)
    |

E117 Over-indented
   --> ai_api_test.py:512:1
    |
510 |         # Note: The new SDK uses 'http_options' for base_url if needed, or just api_key
511 |         if base_url:
512 |              client = genai.Client(api_key=api_key, http_options={'api_endpoint': base_url})
    | ^^^^^^^^^^^^^
513 |         else:
514 |              client = genai.Client(api_key=api_key)
    |

E111 Indentation is not a multiple of 4
   --> ai_api_test.py:514:1
    |
512 |              client = genai.Client(api_key=api_key, http_options={'api_endpoint': base_url})
513 |         else:
514 |              client = genai.Client(api_key=api_key)
    | ^^^^^^^^^^^^^
515 |
516 |         _describe_gemini_models(client, model_name, messages)
    |

E117 Over-indented
   --> ai_api_test.py:514:1
    |
512 |              client = genai.Client(api_key=api_key, http_options={'api_endpoint': base_url})
513 |         else:
514 |              client = genai.Client(api_key=api_key)
    | ^^^^^^^^^^^^^
515 |
516 |         _describe_gemini_models(client, model_name, messages)
    |

PLR0904 Too many public methods (54 > 20)
    --> core\session_manager.py:137:1
     |
 137 | / class SessionManager:
 138 | |     """
 139 | |     Refactored SessionManager that orchestrates specialized managers.
 140 | |
 141 | |     PHASE 5.1 OPTIMIZATION: Enhanced with intelligent component caching to reduce
 142 | |     initialization overhead from 34.59s to <12s. Implements session state persistence
 143 | |     and component reuse for dramatic performance improvement.
 144 | |
 145 | |     This new SessionManager delegates responsibilities to specialized managers:
 146 | |     - DatabaseManager: Handles all database operations (with connection pooling cache)
 147 | |     - BrowserManager: Handles all browser/WebDriver operations (with instance reuse)
 148 | |     - APIManager: Handles all API interactions and user identifiers (with session cache)
 149 | |     - SessionValidator: Handles session validation and readiness checks (with state cache)
 150 | |
 151 | |     Performance optimizations:
 152 | |     - Component caching with intelligent TTL management
 153 | |     - Session state persistence across test runs
 154 | |     - Lazy initialization for non-critical components
 155 | |     - Background connection warming
 156 | |
 157 | |     PHASE 5.4 STATE MACHINE: Session lifecycle now follows explicit
 158 | |     states (UNINITIALIZED â†’ RECOVERING â†’ READY, with DEGRADED for
 159 | |     hard failures). Callers invoke guard_action() before session-level
 160 | |     work so exec_actn() can reset degraded sessions automatically.
 161 | |     """
 162 | |
 163 | |     ESSENTIAL_SESSION_COOKIES: tuple[str, str] = ("ANCSESSIONID", "SecureATT")
 164 | |
 165 | |     def __init__(self, db_path: Optional[str] = None):
 166 | |         """
 167 | |         Initialize the SessionManager with optimized component creation.
 168 | |
 169 | |         PHASE 5.1: Uses intelligent caching to reuse expensive components
 170 | |         across multiple SessionManager instances.
 171 | |
 172 | |         Args:
 173 | |             db_path: Optional database path override
 174 | |         """
 175 | |         start_time = time.time()
 176 | |         logger.debug("Initializing optimized SessionManager...")
 177 | |
 178 | |         # PHASE 5.1: Use cached component managers for dramatic performance improvement
 179 | |         self.db_manager = self._get_cached_database_manager(db_path)
 180 | |         self.browser_manager = self._get_cached_browser_manager()
 181 | |         self.api_manager = self._get_cached_api_manager()
 182 | |         self.validator = self._get_cached_session_validator()
 183 | |
 184 | |         # Session state
 185 | |         self.session_ready: bool = False
 186 | |         self.session_start_time: Optional[float] = None
 187 | |
 188 | |         # Lifecycle state tracking for guard enforcement
 189 | |         self._state_lock = threading.Lock()
 190 | |         self._state: SessionLifecycleState = SessionLifecycleState.UNINITIALIZED
 191 | |         self._state_reason: str = "Session not initialized"
 192 | |         self._state_changed_at: float = time.time()
 193 | |
 194 | |         # PHASE 5.1: Session state caching for performance
 195 | |         self._last_readiness_check: Optional[float] = None
 196 | |         self._cached_session_state: dict[str, Any] = {}
 197 | |
 198 | |         # Cookie sync tracking (explicit defaults for recovery logic)
 199 | |         self._last_cookie_sync_time: float = 0.0
 200 | |         self._session_cookies_synced: bool = False
 201 | |
 202 | |         # âš¡ OPTIMIZATION 1: Pre-cached CSRF token for Action 6 performance
 203 | |         self._cached_csrf_token: Optional[str] = None
 204 | |         self._csrf_cache_time: float = 0.0
 205 | |         self._csrf_cache_duration: float = 300.0  # 5-minute cache
 206 | |
 207 | |         # Performance monitoring attributes shared with actions
 208 | |         self._response_times: list[float] = []
 209 | |         self._avg_response_time: float = 0.0
 210 | |         self._recent_slow_calls: int = 0
 211 | |
 212 | |         # Configuration (cached access)
 213 | |         self.ancestry_username: str = config_schema.api.username
 214 | |         self.ancestry_password: str = config_schema.api.password
 215 | |
 216 | |         # Database state tracking (from old SessionManager)
 217 | |         self._db_init_attempted: bool = False
 218 | |         self._db_ready: bool = False
 219 | |
 220 | |         # Identifier logging flags (from old SessionManager)
 221 | |         self._profile_id_logged: bool = False
 222 | |         self._uuid_logged: bool = False
 223 | |         self._tree_id_logged: bool = False
 224 | |         self._owner_logged: bool = False
 225 | |
 226 | |         # Initialize rate limiter (use global singleton for all API calls)
 227 | |         self.rate_limiter = self._initialize_rate_limiter()
 228 | |
 229 | |         # Alias for backward compatibility with code that references dynamic_rate_limiter
 230 | |         # Both attributes point to the same RateLimiter instance
 231 | |         self.dynamic_rate_limiter = self.rate_limiter
 232 | |
 233 | |         # UNIVERSAL SESSION HEALTH MONITORING (moved from action6-specific to universal)
 234 | |         self.session_health_monitor: SessionHealthMonitor = {
 235 | |             'is_alive': threading.Event(),
 236 | |             'death_detected': threading.Event(),
 237 | |             'last_heartbeat': time.time(),
 238 | |             'heartbeat_interval': 30,  # Check every 30 seconds
 239 | |             'death_cascade_halt': threading.Event(),
 240 | |             'death_timestamp': None,
 241 | |             'parallel_operations': 0,
 242 | |             'death_cascade_count': 0
 243 | |         }
 244 | |         self.session_health_monitor['is_alive'].set()  # Initially alive
 245 | |
 246 | |         self._metrics_exporter_started = False
 247 | |
 248 | |         # === ENHANCED SESSION CAPABILITIES ===
 249 | |         # JavaScript error monitoring
 250 | |         self.last_js_error_check: datetime = datetime.now(timezone.utc)
 251 | |
 252 | |         # CSRF token caching for performance optimization
 253 | |         self._cached_csrf_token: Optional[str] = None
 254 | |         self._csrf_cache_time: float = 0
 255 | |         self._csrf_cache_duration: float = 300  # 5 minutes
 256 | |
 257 | |         # Initialize enhanced requests session with advanced configuration
 258 | |         self._initialize_enhanced_requests_session()
 259 | |
 260 | |         # Initialize CloudScraper for anti-bot protection
 261 | |         self._initialize_cloudscraper()
 262 | |
 263 | |         # PHASE 5.1: Only initialize database if not already cached and ready
 264 | |         if not self.db_manager.is_ready:
 265 | |             self.db_manager.ensure_ready()
 266 | |
 267 | |         self._update_session_metrics(force_zero=True)
 268 | |         self._ensure_metrics_exporter()
 269 | |
 270 | |         init_time = time.time() - start_time
 271 | |         logger.debug(
 272 | |             f"Optimized SessionManager created in {init_time:.3f}s: ID={id(self)}"
 273 | |         )
 274 | |
 275 | |     @staticmethod
 276 | |     @cached_database_manager()
 277 | |     def _get_cached_database_manager(
 278 | |         db_path: Optional[str] = None
 279 | |     ) -> "DatabaseManager":
 280 | |         """Get cached DatabaseManager instance"""
 281 | |         logger.debug("Creating/retrieving DatabaseManager from cache")
 282 | |         return DatabaseManager(db_path)
 283 | |
 284 | |     @staticmethod
 285 | |     @cached_browser_manager()
 286 | |     def _get_cached_browser_manager() -> "BrowserManager":
 287 | |         """Get cached BrowserManager instance"""
 288 | |         logger.debug("Creating/retrieving BrowserManager from cache")
 289 | |         return BrowserManager()
 290 | |
 291 | |     @staticmethod
 292 | |     @cached_api_manager()
 293 | |     def _get_cached_api_manager() -> "APIManager":
 294 | |         """Get cached APIManager instance"""
 295 | |         logger.debug("Creating/retrieving APIManager from cache")
 296 | |         return APIManager()
 297 | |
 298 | |     @staticmethod
 299 | |     @cached_session_validator()
 300 | |     def _get_cached_session_validator() -> "SessionValidator":
 301 | |         """Get cached SessionValidator instance"""
 302 | |         logger.debug("Creating/retrieving SessionValidator from cache")
 303 | |         return SessionValidator()
 304 | |
 305 | |     def _initialize_rate_limiter(self) -> Optional[Any]:
 306 | |         """Create or reuse the adaptive rate limiter configured for this session."""
 307 | |
 308 | |         get_rate_limiter = self._resolve_rate_limiter_factory()
 309 | |         if not get_rate_limiter:
 310 | |             return None
 311 | |
 312 | |         batch_threshold = self._resolve_batch_threshold()
 313 | |         success_threshold = self._determine_success_threshold(batch_threshold)
 314 | |
 315 | |         safe_rps, allow_aggressive, desired_rate = self._determine_rate_profile()
 316 | |         min_fill_rate, max_fill_rate = self._compute_fill_rates(
 317 | |             safe_rps, allow_aggressive, desired_rate
 318 | |         )
 319 | |
 320 | |         endpoint_profiles = self._build_endpoint_profile_config()
 321 | |         self._log_endpoint_rate_cap(endpoint_profiles)
 322 | |
 323 | |         bucket_capacity = getattr(config_schema.api, "token_bucket_capacity", 10.0)
 324 | |         initial_fill_rate = min(safe_rps, max_fill_rate)
 325 | |
 326 | |         limiter = get_rate_limiter(
 327 | |             initial_fill_rate=initial_fill_rate,
 328 | |             success_threshold=success_threshold,
 329 | |             min_fill_rate=min_fill_rate,
 330 | |             max_fill_rate=max_fill_rate,
 331 | |             capacity=bucket_capacity,
 332 | |             endpoint_profiles=endpoint_profiles,
 333 | |         )
 334 | |
 335 | |         if limiter:
 336 | |             logger.debug(
 337 | |                 "AdaptiveRateLimiter bound to session (success_threshold=%d)",
 338 | |                 limiter.success_threshold,
 339 | |             )
 340 | |
 341 | |         return limiter
 342 | |
 343 | |     @staticmethod
 344 | |     def _get_utils_attr(attr_name: str) -> Any:
 345 | |         """Safely retrieve an attribute from the utils module."""
 346 | |
 347 | |         utils_module = _load_utils_module()
 348 | |         try:
 349 | |             return getattr(utils_module, attr_name)
 350 | |         except AttributeError as exc:  # pragma: no cover - defensive logging
 351 | |             raise AttributeError(f"utils module missing attribute '{attr_name}'") from exc
 352 | |
 353 | |     @staticmethod
 354 | |     def _resolve_rate_limiter_factory() -> Optional[Callable[..., Any]]:
 355 | |         """Import the rate limiter factory if it is available."""
 356 | |
 357 | |         try:
 358 | |             return SessionManager._get_utils_attr("get_rate_limiter")
 359 | |         except (ImportError, ModuleNotFoundError, AttributeError):
 360 | |             return None
 361 | |
 362 | |     @staticmethod
 363 | |     def _resolve_batch_threshold() -> int:
 364 | |         """Derive the base batch threshold from configuration."""
 365 | |
 366 | |         batch_threshold = getattr(config_schema, "batch_size", 50) or 50
 367 | |         return max(int(batch_threshold), 1)
 368 | |
 369 | |     @staticmethod
 370 | |     def _determine_success_threshold(batch_threshold: int) -> int:
 371 | |         """Resolve success threshold with configuration overrides."""
 372 | |
 373 | |         configured_threshold = getattr(
 374 | |             getattr(config_schema, "api", None),
 375 | |             "token_bucket_success_threshold",
 376 | |             None,
 377 | |         )
 378 | |         if isinstance(configured_threshold, int) and configured_threshold > 0:
 379 | |             return configured_threshold
 380 | |         return max(batch_threshold, 10)
 381 | |
 382 | |     @staticmethod
 383 | |     def _determine_rate_profile() -> tuple[float, bool, float]:
 384 | |         """Resolve rate profile, aggressive allowances, and desired fill rate."""
 385 | |
 386 | |         safe_rps = getattr(config_schema.api, "requests_per_second", 0.3) or 0.3
 387 | |         speed_profile = str(getattr(config_schema.api, "speed_profile", "safe")).lower()
 388 | |         allow_unsafe = bool(getattr(config_schema.api, "allow_unsafe_rate_limit", False))
 389 | |         allow_aggressive = allow_unsafe or speed_profile in {"max", "aggressive", "experimental"}
 390 | |         desired_rate = getattr(config_schema.api, "token_bucket_fill_rate", None) or safe_rps
 391 | |         return safe_rps, allow_aggressive, desired_rate
 392 | |
 393 | |     @staticmethod
 394 | |     def _compute_fill_rates(
 395 | |         safe_rps: float, allow_aggressive: bool, desired_rate: float
 396 | |     ) -> tuple[float, float]:
 397 | |         """Calculate min/max fill rates with safeguards."""
 398 | |
 399 | |         min_fill_rate = max(0.05, safe_rps * 0.25)
 400 | |         max_fill_rate = desired_rate if allow_aggressive else safe_rps
 401 | |
 402 | |         if max_fill_rate < min_fill_rate:
 403 | |             min_fill_rate = max(0.05, max_fill_rate * 0.5)
 404 | |
 405 | |         return min_fill_rate, max_fill_rate
 406 | |
 407 | |     def _log_endpoint_rate_cap(self, endpoint_profiles: dict[str, dict[str, Any]]) -> None:
 408 | |         """Log derived endpoint rate caps for observability."""
 409 | |
 410 | |         endpoint_rate_cap = self._calculate_endpoint_rate_cap(endpoint_profiles)
 411 | |         if endpoint_rate_cap is not None:
 412 | |             logger.debug(
 413 | |                 "Endpoint-specific throttle floor detected: %.3f req/s", endpoint_rate_cap
 414 | |             )
 415 | |
 416 | |     @staticmethod
 417 | |     def _build_endpoint_profile_config() -> dict[str, dict[str, Any]]:
 418 | |         """Normalize endpoint throttle profiles from configuration."""
 419 | |
 420 | |         endpoint_profiles_raw = getattr(config_schema.api, "endpoint_throttle_profiles", {})
 421 | |         if not isinstance(endpoint_profiles_raw, dict):
 422 | |             return {}
 423 | |
 424 | |         return {
 425 | |             key: dict(value)
 426 | |             for key, value in endpoint_profiles_raw.items()
 427 | |             if isinstance(key, str) and isinstance(value, dict)
 428 | |         }
 429 | |
 430 | |     @staticmethod
 431 | |     def _calculate_endpoint_rate_cap(endpoint_profiles: dict[str, dict[str, Any]]) -> Optional[float]:
 432 | |         """Derive the tightest rate cap from endpoint throttle definitions."""
 433 | |
 434 | |         endpoint_rate_cap: Optional[float] = None
 435 | |         for profile in endpoint_profiles.values():
 436 | |             max_rate_val = profile.get("max_rate")
 437 | |             min_interval_val = profile.get("min_interval")
 438 | |             candidate_rates: list[float] = []
 439 | |
 440 | |             if isinstance(max_rate_val, (int, float)) and max_rate_val > 0:
 441 | |                 candidate_rates.append(float(max_rate_val))
 442 | |             if isinstance(min_interval_val, (int, float)) and min_interval_val > 0:
 443 | |                 candidate_rates.append(1.0 / float(min_interval_val))
 444 | |
 445 | |             if candidate_rates:
 446 | |                 cap_candidate = min(candidate_rates)
 447 | |                 endpoint_rate_cap = cap_candidate if endpoint_rate_cap is None else min(endpoint_rate_cap, cap_candidate)
 448 | |
 449 | |         return endpoint_rate_cap
 450 | |
 451 | |     def _initialize_enhanced_requests_session(self) -> None:
 452 | |         """
 453 | |         Initialize enhanced requests session with advanced configuration.
 454 | |         Includes connection pooling, retry strategies, and performance optimizations.
 455 | |         """
 456 | |         logger.debug("Initializing enhanced requests session...")
 457 | |
 458 | |         # Enhanced retry strategy with more comprehensive status codes
 459 | |         # Advanced HTTPAdapter with connection pooling (no urllib3 retries)
 460 | |         # Retry logic handled at application level in utils.py for consistency
 461 | |         adapter = HTTPAdapter(
 462 | |             pool_connections=20,
 463 | |             pool_maxsize=50,
 464 | |             max_retries=0  # Application handles retries
 465 | |         )
 466 | |
 467 | |         # Apply adapter to API manager's requests session
 468 | |         if hasattr(self.api_manager, '_requests_session'):
 469 | |             self.api_manager._requests_session.mount("http://", adapter)
 470 | |             self.api_manager._requests_session.mount("https://", adapter)
 471 | |             logger.debug("Enhanced requests session configuration applied to APIManager")
 472 | |         else:
 473 | |             logger.warning("APIManager requests session not found - creating fallback")
 474 | |             # Create fallback session if APIManager doesn't have one
 475 | |             self.api_manager._requests_session = requests.Session()
 476 | |             self.api_manager._requests_session.mount("http://", adapter)
 477 | |             self.api_manager._requests_session.mount("https://", adapter)
 478 | |
 479 | |     def _initialize_cloudscraper(self) -> None:
 480 | |         """
 481 | |         Initialize CloudScraper for anti-bot protection.
 482 | |         Provides enhanced capabilities for bypassing CloudFlare and other protections.
 483 | |         """
 484 | |         if cloudscraper is None:
 485 | |             logger.debug("CloudScraper not available - skipping initialization")
 486 | |             self._scraper = None
 487 | |             return
 488 | |
 489 | |         logger.debug("Initializing CloudScraper with anti-bot protection...")
 490 | |
 491 | |         try:
 492 | |             # Create CloudScraper with browser fingerprinting
 493 | |             self._scraper = cast(Any, cloudscraper).create_scraper(
 494 | |                 browser={"browser": "chrome", "platform": "windows", "desktop": True},
 495 | |                 delay=10,
 496 | |             )
 497 | |
 498 | |             # Apply HTTP adapter to CloudScraper (no urllib3 retries - application handles)
 499 | |             scraper_adapter = HTTPAdapter(max_retries=0)
 500 | |             self._scraper.mount("http://", scraper_adapter)
 501 | |             self._scraper.mount("https://", scraper_adapter)
 502 | |
 503 | |             logger.debug("CloudScraper initialized successfully with connection pooling")
 504 | |
 505 | |         except Exception as scraper_init_e:
 506 | |             logger.error(
 507 | |                 f"Failed to initialize CloudScraper: {scraper_init_e}",
 508 | |                 exc_info=True,
 509 | |             )
 510 | |             self._scraper = None
 511 | |
 512 | |     def ensure_db_ready(self) -> bool:
 513 | |         """
 514 | |         Ensure database is ready.
 515 | |
 516 | |         Returns:
 517 | |             bool: True if database is ready, False otherwise
 518 | |         """
 519 | |         return self.db_manager.ensure_ready()
 520 | |
 521 | |     def start_browser(self, action_name: Optional[str] = None) -> bool:
 522 | |         """
 523 | |         Start the browser session.
 524 | |
 525 | |         Args:
 526 | |             action_name: Optional name of the action for logging
 527 | |
 528 | |         Returns:
 529 | |             bool: True if browser started successfully, False otherwise
 530 | |         """
 531 | |         # Reset logged flags when starting browser
 532 | |         self._reset_logged_flags()
 533 | |         return self.browser_manager.start_browser(action_name)
 534 | |
 535 | |     def close_browser(self) -> None:
 536 | |         """Close the browser session without affecting database."""
 537 | |         self.browser_manager.close_browser()
 538 | |         self._reset_cookie_sync_state("browser_close")
 539 | |
 540 | |     def start_sess(self, action_name: Optional[str] = None) -> bool:
 541 | |         """
 542 | |         Start session (database and browser if needed).
 543 | |
 544 | |         Args:
 545 | |             action_name: Optional name of the action for logging
 546 | |
 547 | |         Returns:
 548 | |             bool: True if session started successfully, False otherwise
 549 | |         """
 550 | |         logger.debug(f"Starting session for: {action_name or 'Unknown Action'}")
 551 | |
 552 | |         # Ensure database is ready
 553 | |         if not self.ensure_db_ready():
 554 | |             logger.error("Failed to ensure database ready.")
 555 | |             return False
 556 | |
 557 | |         # Start browser if needed
 558 | |         if self.browser_manager.browser_needed:
 559 | |             browser_success = self.start_browser(action_name)
 560 | |             if not browser_success:
 561 | |                 logger.error("Failed to start browser.")
 562 | |                 return False
 563 | |
 564 | |         # Mark session as started
 565 | |         self.session_start_time = time.time()
 566 | |         self._update_session_metrics()
 567 | |
 568 | |         return True
 569 | |
 570 | |     # --- Lifecycle guard helpers ---
 571 | |
 572 | |     def _transition_state(self, target: SessionLifecycleState, reason: str) -> None:
 573 | |         """Internal helper to update lifecycle state with logging."""
 574 | |
 575 | |         with self._state_lock:
 576 | |             previous = self._state
 577 | |             self._state = target
 578 | |             self._state_reason = reason or previous.value
 579 | |             self._state_changed_at = time.time()
 580 | |
 581 | |             if target == SessionLifecycleState.READY:
 582 | |                 self.session_ready = True
 583 | |             else:
 584 | |                 self.session_ready = False
 585 | |
 586 | |         if previous != target:
 587 | |             logger.debug(
 588 | |                 "Session lifecycle transition: %s â†’ %s (%s)",
 589 | |                 previous.value,
 590 | |                 target.value,
 591 | |                 reason,
 592 | |             )
 593 | |
 594 | |     def lifecycle_state(self) -> SessionLifecycleState:
 595 | |         """Return the current lifecycle state (thread-safe)."""
 596 | |
 597 | |         with self._state_lock:
 598 | |             return self._state
 599 | |
 600 | |     def get_state_snapshot(self) -> dict[str, Any]:
 601 | |         """Provide a snapshot of lifecycle state for diagnostics."""
 602 | |
 603 | |         with self._state_lock:
 604 | |             return {
 605 | |                 "state": self._state.value,
 606 | |                 "reason": self._state_reason,
 607 | |                 "changed_at": self._state_changed_at,
 608 | |             }
 609 | |
 610 | |     def request_recovery(self, reason: str) -> None:
 611 | |         """Reset lifecycle state to UNINITIALIZED before rebuilding."""
 612 | |
 613 | |         self._last_readiness_check = None
 614 | |         self._transition_state(SessionLifecycleState.UNINITIALIZED, reason)
 615 | |
 616 | |     def guard_action(self, required_state: str, action_name: str) -> bool:
 617 | |         """Guard execution based on lifecycle state requirements."""
 618 | |
 619 | |         normalized_required = (required_state or "").lower()
 620 | |         if normalized_required == "db_ready":
 621 | |             return True
 622 | |
 623 | |         current_state = self.lifecycle_state()
 624 | |         if current_state == SessionLifecycleState.DEGRADED:
 625 | |             logger.warning(
 626 | |                 "Action %s requires %s but session is DEGRADED; resetting lifecycle state before continuing",
 627 | |                 action_name,
 628 | |                 normalized_required,
 629 | |             )
 630 | |             self.request_recovery(f"{action_name} reset from DEGRADED state")
 631 | |             return True
 632 | |
 633 | |         if current_state == SessionLifecycleState.UNINITIALIZED and normalized_required in {"driver_ready", "session_ready"}:
 634 | |             logger.debug(
 635 | |                 "Action %s will bootstrap session lifecycle (state=%s)",
 636 | |                 action_name,
 637 | |                 current_state.value,
 638 | |             )
 639 | |
 640 | |         return True
 641 | |
 642 | |     @timeout_protection(timeout=120)  # Increased timeout for complex operations like Action 7
 643 | |     @graceful_degradation(fallback_value=False)
 644 | |     @error_context("ensure_session_ready")
 645 | |     def _check_cached_readiness(self, action_name: Optional[str]) -> Optional[bool]:
 646 | |         """Check if we can use cached readiness state.
 647 | |
 648 | |         Returns:
 649 | |             True if cached state is valid and ready, False if invalid, None if no cache
 650 | |         """
 651 | |         if self._last_readiness_check is None:
 652 | |             return None
 653 | |
 654 | |         time_since_check = time.time() - self._last_readiness_check
 655 | |         cache_duration = 60  # Use consistent 60-second cache for all actions
 656 | |
 657 | |         if time_since_check >= cache_duration or not self.session_ready:
 658 | |             return None
 659 | |
 660 | |         # Validate that the cached state is still accurate
 661 | |         if self.browser_manager.browser_needed and not self.browser_manager.is_session_valid():
 662 | |             logger.debug(
 663 | |                 f"Cached session readiness invalid - driver session expired (age: {time_since_check:.1f}s)"
 664 | |             )
 665 | |             self._last_readiness_check = None
 666 | |             self._transition_state(
 667 | |                 SessionLifecycleState.DEGRADED,
 668 | |                 "Driver session expired during cached readiness check",
 669 | |             )
 670 | |             return False
 671 | |
 672 | |         logger.debug(
 673 | |             f"Using cached session readiness (age: {time_since_check:.1f}s, action: {action_name})"
 674 | |         )
 675 | |         return True
 676 | |
 677 | |     def _perform_readiness_validation(self, action_name: Optional[str], skip_csrf: bool) -> bool:
 678 | |         """Perform readiness checks and identifier retrieval.
 679 | |
 680 | |         Returns:
 681 | |             True if all checks pass, False otherwise
 682 | |         """
 683 | |         # PHASE 5.1: Optimized readiness checks with circuit breaker pattern
 684 | |         try:
 685 | |             ready_checks_ok = self.validator.perform_readiness_checks(
 686 | |                 self.browser_manager, self.api_manager, self, action_name, skip_csrf=skip_csrf
 687 | |             )
 688 | |
 689 | |             if not ready_checks_ok:
 690 | |                 logger.error("Readiness checks failed.")
 691 | |                 return False
 692 | |
 693 | |         except Exception as e:
 694 | |             logger.critical(f"Exception in readiness checks: {e}", exc_info=True)
 695 | |             return False
 696 | |
 697 | |         # PHASE 5.1: Optimized identifier retrieval with caching
 698 | |         identifiers_ok = self._retrieve_identifiers()
 699 | |         if not identifiers_ok:
 700 | |             logger.warning("Some identifiers could not be retrieved.")
 701 | |
 702 | |         # Retrieve tree owner if configured (with caching)
 703 | |         owner_ok = True
 704 | |         if config_schema.api.tree_name:
 705 | |             owner_ok = self._retrieve_tree_owner()
 706 | |             if not owner_ok:
 707 | |                 logger.warning("Tree owner name could not be retrieved.")
 708 | |
 709 | |         # âš¡ OPTIMIZATION 1: Pre-cache CSRF token during session setup
 710 | |         if ready_checks_ok and identifiers_ok:
 711 | |             self._precache_csrf_token()
 712 | |
 713 | |         return ready_checks_ok and identifiers_ok and owner_ok
 714 | |
 715 | |     def ensure_session_ready(self, action_name: Optional[str] = None, skip_csrf: bool = False) -> bool:
 716 | |         """
 717 | |         Ensure the session is ready for operations.
 718 | |
 719 | |         PHASE 5.1 OPTIMIZATION: Uses intelligent caching to bypass expensive
 720 | |         readiness checks when session state is known to be valid.
 721 | |
 722 | |         Args:
 723 | |             action_name: Optional name of the action for logging
 724 | |             skip_csrf: Skip CSRF token validation (for actions that don't need it)
 725 | |
 726 | |         Returns:
 727 | |             bool: True if session is ready, False otherwise
 728 | |         """
 729 | |         start_time = time.time()
 730 | |         # Removed duplicate logging - browser_manager will log the action
 731 | |
 732 | |         # MINIMAL FIX: Set browser_needed to True for session operations
 733 | |         self.browser_manager.browser_needed = True
 734 | |
 735 | |         # PHASE 5.1: Check cached session state first
 736 | |         cached_result = self._check_cached_readiness(action_name)
 737 | |         if cached_result is not None:
 738 | |             self._update_session_metrics()
 739 | |             return cached_result
 740 | |
 741 | |         readiness_reason = f"{action_name or 'unknown_action'} readiness validation"
 742 | |         self._transition_state(SessionLifecycleState.RECOVERING, readiness_reason)
 743 | |
 744 | |         # Ensure driver is live if browser is needed (with optimization)
 745 | |         if self.browser_manager.browser_needed and not self.browser_manager.ensure_driver_live(action_name):
 746 | |             logger.error("Failed to ensure driver live.")
 747 | |             self._transition_state(
 748 | |                 SessionLifecycleState.DEGRADED,
 749 | |                 "Driver live check failed",
 750 | |             )
 751 | |             self._update_session_metrics()
 752 | |             return False
 753 | |
 754 | |         # Perform readiness validation
 755 | |         readiness_ok = self._perform_readiness_validation(action_name, skip_csrf)
 756 | |
 757 | |         if readiness_ok:
 758 | |             self._transition_state(SessionLifecycleState.READY, readiness_reason)
 759 | |         else:
 760 | |             self._transition_state(SessionLifecycleState.DEGRADED, readiness_reason)
 761 | |         self.session_ready = readiness_ok
 762 | |
 763 | |         # PHASE 5.1: Cache the readiness check result
 764 | |         self._last_readiness_check = time.time()
 765 | |
 766 | |         check_time = time.time() - start_time
 767 | |         logger.debug(
 768 | |             f"Session readiness check completed in {check_time:.3f}s, status: {self.session_ready}"
 769 | |         )
 770 | |         self._update_session_metrics()
 771 | |         return readiness_ok
 772 | |
 773 | |     def verify_sess(self) -> bool:
 774 | |         """
 775 | |         Verify session status using login_status function.
 776 | |
 777 | |         Returns:
 778 | |             bool: True if session is valid, False otherwise
 779 | |         """
 780 | |         logger.debug("Verifying session status (using login_status)...")
 781 | |         try:
 782 | |             # Import login_status locally to avoid circular imports
 783 | |             from utils import login_status
 784 | |
 785 | |             login_ok = login_status(self, disable_ui_fallback=False)
 786 | |             if login_ok is True:
 787 | |                 logger.debug("Session verification successful (logged in).")
 788 | |                 return True
 789 | |             if login_ok is False:
 790 | |                 logger.warning("Session verification failed (user not logged in).")
 791 | |                 return False
 792 | |             # login_ok is None
 793 | |             logger.error("Session verification failed critically (login_status returned None).")
 794 | |             return False
 795 | |         except Exception as e:
 796 | |             logger.error(f"Unexpected error during session verification: {e}", exc_info=True)
 797 | |             return False
 798 | |
 799 | |     def is_sess_valid(self) -> bool:
 800 | |         """
 801 | |         Enhanced session validity check with recovery capabilities.
 802 | |
 803 | |         Checks if driver exists and is responsive, with automatic recovery
 804 | |         for invalid sessions during long-running operations.
 805 | |
 806 | |         Returns:
 807 | |             bool: True if driver exists and is responsive, False otherwise
 808 | |         """
 809 | |         # Simple check - verify driver exists
 810 | |         if self.driver is None:
 811 | |             return False
 812 | |
 813 | |         # Enhanced check - verify driver is responsive
 814 | |         try:
 815 | |             # Quick responsiveness test
 816 | |             _ = self.driver.current_url
 817 | |             return True
 818 | |         except Exception as e:
 819 | |             logger.warning(f"ðŸ”Œ WebDriver session appears invalid: {e}")
 820 | |             # Attempt session recovery for long-running operations
 821 | |             if self._should_attempt_recovery():
 822 | |                 logger.info("ðŸ”„ Attempting automatic session recovery...")
 823 | |                 if self._attempt_session_recovery(reason="browser_error"):
 824 | |                     logger.info("âœ… Session recovery successful")
 825 | |                     return True
 826 | |                 logger.error("âŒ Session recovery failed")
 827 | |             else:
 828 | |                 logger.debug("â­ï¸  Skipping session recovery (not in long-running operation)")
 829 | |             return False
 830 | |
 831 | |     def _should_attempt_recovery(self) -> bool:
 832 | |         """
 833 | |         Determine if session recovery should be attempted.
 834 | |
 835 | |         Returns:
 836 | |             bool: True if recovery should be attempted
 837 | |         """
 838 | |         # Attempt recovery any time a session that was marked ready becomes invalid
 839 | |         return bool(self.session_ready)
 840 | |
 841 | |     def _attempt_session_recovery(self, reason: str = "browser_error") -> bool:
 842 | |         """
 843 | |         Attempt to recover an invalid WebDriver session.
 844 | |
 845 | |         Returns:
 846 | |             bool: True if recovery successful, False otherwise
 847 | |         """
 848 | |         try:
 849 | |             logger.debug("Closing invalid browser session...")
 850 | |             self.close_browser()
 851 | |
 852 | |             logger.debug("Starting new browser session...")
 853 | |             if not self.start_browser("session_recovery"):
 854 | |                 logger.error("Browser restart failed during session recovery")
 855 | |                 return False
 856 | |
 857 | |             logger.debug("Browser recovery successful, validating authentication state...")
 858 | |
 859 | |             from utils import log_in, login_status
 860 | |
 861 | |             login_ok = login_status(self, disable_ui_fallback=False)
 862 | |             if login_ok is not True:
 863 | |                 logger.info(
 864 | |                     "Recovered browser not authenticated (login_status=%s) - initiating login flow",
 865 | |                     login_ok,
 866 | |                 )
 867 | |                 login_result = log_in(self)
 868 | |                 if login_result != "LOGIN_SUCCEEDED":
 869 | |                     logger.error(
 870 | |                         "Re-authentication failed after browser recovery (result=%s)",
 871 | |                         login_result,
 872 | |                     )
 873 | |                     return False
 874 | |
 875 | |             if not self._finalize_recovered_session_state():
 876 | |                 logger.error("Session recovery failed validation (cookies/CSRF missing)")
 877 | |                 return False
 878 | |
 879 | |             self.session_start_time = time.time()
 880 | |             self._update_session_metrics()
 881 | |             self._record_session_refresh_metric(reason)
 882 | |             logger.info("Session recovery and re-authentication successful")
 883 | |             return True
 884 | |
 885 | |         except Exception as e:
 886 | |             logger.error(f"Session recovery failed: {e}", exc_info=True)
 887 | |
 888 | |         return False
 889 | |
 890 | |     def attempt_session_recovery(self, reason: str = "browser_error") -> bool:
 891 | |         """Public wrapper so callers avoid touching the private helper."""
 892 | |
 893 | |         return self._attempt_session_recovery(reason=reason)
 894 | |
 895 | |     # UNIVERSAL SESSION HEALTH MONITORING METHODS
 896 | |     def check_session_health(self) -> bool:
 897 | |         """
 898 | |         Universal session health monitoring that detects session death and prevents
 899 | |         cascade failures during long-running operations.
 900 | |
 901 | |         This replaces action6-specific monitoring with universal monitoring.
 902 | |         """
 903 | |         self._update_session_metrics()
 904 | |         try:
 905 | |             # Quick session validation first
 906 | |             if not self.is_sess_valid():
 907 | |                 if not self.session_health_monitor['death_detected'].is_set():
 908 | |                     self.session_health_monitor['death_detected'].set()
 909 | |                     self.session_health_monitor['is_alive'].clear()
 910 | |                     self.session_health_monitor['death_timestamp'] = time.time()
 911 | |                     logger.critical(
 912 | |                         f"ðŸš¨ SESSION DEATH DETECTED at {time.strftime('%H:%M:%S')}"
 913 | |                         f" - Universal session health monitoring triggered"
 914 | |                     )
 915 | |                 return False
 916 | |
 917 | |             # Update heartbeat if session is alive
 918 | |             self.session_health_monitor['last_heartbeat'] = time.time()
 919 | |             return True
 920 | |
 921 | |         except Exception as exc:
 922 | |             logger.error(f"Session health check failed: {exc}")
 923 | |             # Assume session is dead on health check failure
 924 | |             if not self.session_health_monitor['death_detected'].is_set():
 925 | |                 self.session_health_monitor['death_detected'].set()
 926 | |                 self.session_health_monitor['is_alive'].clear()
 927 | |                 self.session_health_monitor['death_timestamp'] = time.time()
 928 | |                 logger.critical("ðŸš¨ SESSION HEALTH CHECK FAILED - Assuming session death")
 929 | |             return False
 930 | |
 931 | |     def is_session_death_cascade(self) -> bool:
 932 | |         """Check if we're in a session death cascade scenario."""
 933 | |         return self.session_health_monitor['death_detected'].is_set()
 934 | |
 935 | |     def should_halt_operations(self) -> bool:
 936 | |         """Determine if operations should halt due to session death."""
 937 | |         if self.is_session_death_cascade():
 938 | |             self.session_health_monitor['death_cascade_count'] += 1
 939 | |
 940 | |             # Halt immediately if session is dead
 941 | |             logger.warning(
 942 | |                 f"âš ï¸  Halting operation due to session death cascade "
 943 | |                 f"(cascade #{self.session_health_monitor['death_cascade_count']})"
 944 | |             )
 945 | |             return True
 946 | |         return False
 947 | |
 948 | |     def reset_session_health_monitoring(self) -> None:
 949 | |         """Reset session health monitoring (used when creating new sessions)."""
 950 | |         self.session_health_monitor['is_alive'].set()
 951 | |         self.session_health_monitor['death_detected'].clear()
 952 | |         self.session_health_monitor['last_heartbeat'] = time.time()
 953 | |         self.session_health_monitor['death_timestamp'] = None
 954 | |         self.session_health_monitor['parallel_operations'] = 0
 955 | |         self.session_health_monitor['death_cascade_count'] = 0
 956 | |         logger.debug("ðŸ”„ Session health monitoring reset for new session")
 957 | |
 958 | |     def _reset_logged_flags(self) -> None:
 959 | |         """Reset flags used to prevent repeated logging of IDs."""
 960 | |         self._profile_id_logged = False
 961 | |         self._uuid_logged = False
 962 | |         self._tree_id_logged = False
 963 | |         self._owner_logged = False
 964 | |
 965 | |     def _retrieve_identifiers(self) -> bool:
 966 | |         """
 967 | |         Retrieve all essential identifiers.
 968 | |
 969 | |         Returns:
 970 | |             bool: True if all identifiers retrieved successfully, False otherwise
 971 | |         """
 972 | |         if not self.is_sess_valid():
 973 | |             logger.error("_retrieve_identifiers: Session is invalid.")
 974 | |             return False
 975 | |
 976 | |         all_ok = True
 977 | |
 978 | |         # Get Profile ID
 979 | |         if not self.my_profile_id:
 980 | |             logger.debug("Retrieving profile ID (ucdmid)...")
 981 | |             profile_id = self.get_my_profile_id()
 982 | |             if not profile_id:
 983 | |                 logger.error("Failed to retrieve profile ID (ucdmid).")
 984 | |                 all_ok = False
 985 | |
 986 | |         # Get UUID
 987 | |         if not self.my_uuid:
 988 | |             logger.debug("Retrieving UUID (testId)...")
 989 | |             uuid_val = self.get_my_uuid()
 990 | |             if not uuid_val:
 991 | |                 logger.error("Failed to retrieve UUID (testId).")
 992 | |                 all_ok = False
 993 | |
 994 | |         # Get Tree ID (only if TREE_NAME is configured)
 995 | |         if config_schema.api.tree_name and not self.my_tree_id:
 996 | |             logger.debug(f"Retrieving tree ID for tree name: '{config_schema.api.tree_name}'...")
 997 | |             try:
 998 | |                 tree_id = self.get_my_tree_id()
 999 | |                 if not tree_id:
1000 | |                     logger.error(f"TREE_NAME '{config_schema.api.tree_name}' configured, but failed to get corresponding tree ID.")
1001 | |                     all_ok = False
1002 | |             except ImportError as tree_id_imp_err:
1003 | |                 logger.error(f"Failed to retrieve tree ID due to import error: {tree_id_imp_err}")
1004 | |                 all_ok = False
1005 | |
1006 | |         return all_ok
1007 | |
1008 | |     def _retrieve_tree_owner(self) -> bool:
1009 | |         """
1010 | |         Retrieve tree owner name.
1011 | |
1012 | |         Returns:
1013 | |             bool: True if tree owner retrieved successfully, False otherwise
1014 | |         """
1015 | |         if not self.is_sess_valid():
1016 | |             logger.error("_retrieve_tree_owner: Session is invalid.")
1017 | |             return False
1018 | |
1019 | |         if not self.my_tree_id:
1020 | |             logger.debug("Cannot retrieve tree owner name: my_tree_id is not set.")
1021 | |             return False
1022 | |
1023 | |         # Only retrieve if not already present
1024 | |         if self.tree_owner_name and self._owner_logged:
1025 | |             return True
1026 | |
1027 | |         logger.debug("Retrieving tree owner name...")
1028 | |         try:
1029 | |             owner_name = self.get_tree_owner(self.my_tree_id)
1030 | |             return bool(owner_name)
1031 | |         except ImportError as owner_imp_err:
1032 | |             logger.error(f"Failed to retrieve tree owner due to import error: {owner_imp_err}")
1033 | |             return False
1034 | |
1035 | |     def _get_current_cookie_names(self) -> set[str]:
1036 | |         """Get current cookie names from driver (lowercase).
1037 | |
1038 | |         Returns:
1039 | |             Set of lowercase cookie names
1040 | |         """
1041 | |         if not self.driver:
1042 | |             return set()
1043 | |         try:
1044 | |             driver = cast(Any, self.driver)
1045 | |             cookies = cast(list[dict[str, Any]], driver.get_cookies())
1046 | |             return {
1047 | |                 cookie["name"].lower()
1048 | |                 for cookie in cookies
1049 | |                 if "name" in cookie
1050 | |             }
1051 | |         except Exception:
1052 | |             return set()
1053 | |
1054 | |     def _check_cookies_available(
1055 | |         self,
1056 | |         required_lower: set[str],
1057 | |         last_missing_str: str
1058 | |     ) -> tuple[bool, str]:
1059 | |         """Check if required cookies are available.
1060 | |
1061 | |         Args:
1062 | |             required_lower: Set of required cookie names (lowercase)
1063 | |             last_missing_str: Last missing cookies string for logging
1064 | |
1065 | |         Returns:
1066 | |             Tuple of (all_found, new_missing_str)
1067 | |         """
1068 | |         current_cookies_lower = self._get_current_cookie_names()
1069 | |         missing_lower = required_lower - current_cookies_lower
1070 | |
1071 | |         if not missing_lower:
1072 | |             return True, ""
1073 | |
1074 | |         # Log missing cookies only if the set changes
1075 | |         missing_str = ", ".join(sorted(missing_lower))
1076 | |         if missing_str != last_missing_str:
1077 | |             logger.debug(f"Still missing cookies: {missing_str}")
1078 | |
1079 | |         return False, missing_str
1080 | |
1081 | |     def _perform_final_cookie_check(
1082 | |         self,
1083 | |         cookie_names: list[str]
1084 | |     ) -> bool:
1085 | |         """Perform final cookie check after timeout.
1086 | |
1087 | |         Args:
1088 | |             cookie_names: List of required cookie names
1089 | |
1090 | |         Returns:
1091 | |             True if all cookies found, False otherwise
1092 | |         """
1093 | |         try:
1094 | |             if not self.is_sess_valid():
1095 | |                 logger.warning(f"Timeout waiting for cookies. Missing: {cookie_names}.")
1096 | |                 return False
1097 | |
1098 | |             current_cookies_lower = self._get_current_cookie_names()
1099 | |             missing_final = [
1100 | |                 name for name in cookie_names
1101 | |                 if name.lower() not in current_cookies_lower
1102 | |             ]
1103 | |
1104 | |             if missing_final:
1105 | |                 logger.warning(f"Timeout waiting for cookies. Missing: {missing_final}.")
1106 | |                 return False
1107 | |
1108 | |             logger.debug("Cookies found in final check after loop (unexpected).")
1109 | |             return True
1110 | |
1111 | |         except Exception:
1112 | |             logger.warning(f"Timeout waiting for cookies. Missing: {cookie_names}.")
1113 | |             return False
1114 | |
1115 | |     def get_cookies(self, cookie_names: list[str], timeout: int = 30) -> bool:
1116 | |         """
1117 | |         Advanced cookie management with timeout and session validation.
1118 | |
1119 | |         Waits for specific cookies to be available with intelligent retry logic
1120 | |         and continuous session validity checking.
1121 | |
1122 | |         Args:
1123 | |             cookie_names: List of cookie names to wait for
1124 | |             timeout: Maximum time to wait in seconds
1125 | |
1126 | |         Returns:
1127 | |             bool: True if all cookies found, False otherwise
1128 | |         """
1129 | |         if not self.driver:
1130 | |             logger.error("get_cookies: WebDriver instance is None.")
1131 | |             return False
1132 | |
1133 | |         start_time = time.time()
1134 | |         logger.debug(f"Waiting up to {timeout}s for cookies: {cookie_names}...")
1135 | |         required_lower = {name.lower() for name in cookie_names}
1136 | |         interval = 0.5
1137 | |         last_missing_str = ""
1138 | |
1139 | |         while time.time() - start_time < timeout:
1140 | |             try:
1141 | |                 if not self.driver:
1142 | |                     logger.warning("Driver became None while waiting for cookies.")
1143 | |                     return False
1144 | |
1145 | |                 all_found, last_missing_str = self._check_cookies_available(
1146 | |                     required_lower, last_missing_str
1147 | |                 )
1148 | |                 if all_found:
1149 | |                     logger.debug(f"All required cookies found: {cookie_names}.")
1150 | |                     return True
1151 | |
1152 | |                 time.sleep(interval)
1153 | |
1154 | |             except WebDriverException as e:
1155 | |                 logger.error(f"WebDriverException while retrieving cookies: {e}")
1156 | |                 if not self.is_sess_valid():
1157 | |                     logger.error("Session invalid after WebDriverException during cookie retrieval.")
1158 | |                     return False
1159 | |                 time.sleep(interval * 2)
1160 | |
1161 | |             except Exception as e:
1162 | |                 logger.error(f"Unexpected error during cookie retrieval: {e}")
1163 | |                 time.sleep(interval * 2)
1164 | |
1165 | |         return self._perform_final_cookie_check(cookie_names)
1166 | |
1167 | |     def _should_skip_cookie_sync(self, current_time: float, force: bool = False) -> bool:
1168 | |         """
1169 | |         Determine if cookie sync should be skipped based on various conditions.
1170 | |
1171 | |         Returns:
1172 | |             True if sync should be skipped, False if sync should proceed
1173 | |         """
1174 | |         # Check 1: Recursion prevention
1175 | |         if hasattr(self, '_in_sync_cookies') and self._in_sync_cookies:
1176 | |             logger.debug("Cookie sync skipped: recursion detected")
1177 | |             return True
1178 | |
1179 | |         # Check 2: Prerequisites validation
1180 | |         if not self.driver or not hasattr(self.api_manager, '_requests_session'):
1181 | |             logger.debug("Cookie sync skipped: driver or requests_session not available")
1182 | |             return True
1183 | |
1184 | |         # Forced sync bypasses cooldown and prior success checks but still
1185 | |         # requires the basic prerequisites above to be satisfied.
1186 | |         if force:
1187 | |             return False
1188 | |
1189 | |         # Check 3: Cooldown period (60 seconds)
1190 | |         # Cookie state rarely changes during normal operation, so we can safely wait 1 minute
1191 | |         # This prevents burst syncs while still allowing updates during long-running sessions
1192 | |         COOKIE_SYNC_COOLDOWN = 60.0  # seconds
1193 | |         if hasattr(self, '_last_cookie_sync_time'):
1194 | |             time_since_last_sync = current_time - self._last_cookie_sync_time
1195 | |             if time_since_last_sync < COOKIE_SYNC_COOLDOWN:
1196 | |                 logger.debug(
1197 | |                     f"Cookie sync skipped: cooldown active "
1198 | |                     f"(last sync: {time_since_last_sync:.1f}s ago, cooldown: {COOKIE_SYNC_COOLDOWN:.0f}s)"
1199 | |                 )
1200 | |                 return True
1201 | |
1202 | |         # Check 4: Already synced for this session
1203 | |         if hasattr(self, '_session_cookies_synced') and self._session_cookies_synced:
1204 | |             logger.debug("Cookie sync skipped: already synced for this session")
1205 | |             return True
1206 | |
1207 | |         return False
1208 | |
1209 | |     def _sync_cookies_to_requests(self, force: bool = False) -> None:
1210 | |         """
1211 | |         Synchronize cookies from WebDriver to requests session.
1212 | |         Only syncs once per session unless forced due to auth errors.
1213 | |
1214 | |         Enhanced with recursion prevention, robust error handling, and cooldown period.
1215 | |         Uses _should_skip_cookie_sync() for clean separation of sync validation logic.
1216 | |
1217 | |         Args:
1218 | |             force: When True, bypass cooldown and prior-success guards while
1219 | |                 still requiring prerequisite browser state.
1220 | |         """
1221 | |         current_time = time.time()
1222 | |
1223 | |         # Check if sync should be skipped
1224 | |         if self._should_skip_cookie_sync(current_time, force=force):
1225 | |             return
1226 | |
1227 | |         try:
1228 | |             # Set recursion prevention flag
1229 | |             self._in_sync_cookies = True
1230 | |
1231 | |             # Get cookies from WebDriver (validated in _should_skip_cookie_sync)
1232 | |             if not self.driver:
1233 | |                 logger.error("Driver not available for cookie sync")
1234 | |                 return
1235 | |
1236 | |             driver = cast(Any, self.driver)
1237 | |             driver_cookies = cast(list[dict[str, Any]], driver.get_cookies())
1238 | |
1239 | |             # Validate cookies were retrieved
1240 | |             if not driver_cookies:
1241 | |                 logger.debug("No cookies retrieved from WebDriver")
1242 | |                 return
1243 | |
1244 | |             # Use helper method for robust cookie syncing
1245 | |             synced_count = self._sync_driver_cookies_to_requests(driver_cookies)
1246 | |
1247 | |             self._session_cookies_synced = True
1248 | |             self._last_cookie_sync_time = current_time  # Track sync time for cooldown
1249 | |             logger.debug(f"Synced {synced_count} cookies from WebDriver to requests session (once per session)")
1250 | |
1251 | |         except Exception as e:
1252 | |             logger.error(f"Failed to sync cookies to requests session: {e}")
1253 | |         finally:
1254 | |             # Always clear recursion flag
1255 | |             if hasattr(self, '_in_sync_cookies'):
1256 | |                 self._in_sync_cookies = False
1257 | |
1258 | |     def sync_cookies_to_requests(self, force: bool = False) -> None:
1259 | |         """Public wrapper that enforces typing-friendly cookie sync access."""
1260 | |
1261 | |         self._sync_cookies_to_requests(force=force)
1262 | |
1263 | |     def force_cookie_resync(self) -> None:
1264 | |         """Force a cookie resync when authentication errors occur."""
1265 | |         self._session_cookies_synced = False
1266 | |         self._sync_cookies_to_requests(force=True)
1267 | |         logger.debug("Forced session cookie resync due to authentication error")
1268 | |
1269 | |     def _reset_cookie_sync_state(self, reason: str = "unspecified") -> None:
1270 | |         """Clear cookie sync flags and cached tokens for reliable recovery."""
1271 | |
1272 | |         self._session_cookies_synced = False
1273 | |         self._last_cookie_sync_time = 0.0
1274 | |
1275 | |         try:
1276 | |             self.api_manager._requests_session.cookies.clear()
1277 | |         except Exception as exc:
1278 | |             logger.debug(
1279 | |                 "Failed to clear requests-session cookies during %s: %s",
1280 | |                 reason,
1281 | |                 exc,
1282 | |             )
1283 | |
1284 | |         self.invalidate_csrf_cache()
1285 | |
1286 | |     def _finalize_recovered_session_state(self) -> bool:
1287 | |         """Ensure cookies/CSRF are available before declaring recovery success."""
1288 | |
1289 | |         essential_cookies = list(self.ESSENTIAL_SESSION_COOKIES)
1290 | |         if not self.get_cookies(essential_cookies, timeout=30):
1291 | |             logger.error(
1292 | |                 "Essential cookies %s missing after session recovery",
1293 | |                 essential_cookies,
1294 | |             )
1295 | |             return False
1296 | |
1297 | |         self.force_cookie_resync()
1298 | |
1299 | |         csrf_token = self.get_csrf()
1300 | |         if not csrf_token:
1301 | |             logger.error("Failed to refresh CSRF token after session recovery")
1302 | |             return False
1303 | |
1304 | |         self._precache_csrf_token()
1305 | |         return True
1306 | |
1307 | |     def _sync_driver_cookies_to_requests(self, driver_cookies: list[dict[str, Any]]) -> int:
1308 | |         """Sync driver cookies to requests session.
1309 | |
1310 | |         Args:
1311 | |             driver_cookies: List of cookies from WebDriver
1312 | |
1313 | |         Returns:
1314 | |             Number of cookies synced
1315 | |         """
1316 | |         self.api_manager._requests_session.cookies.clear()
1317 | |         synced_count = 0
1318 | |
1319 | |         for cookie in driver_cookies:
1320 | |             name = cookie.get("name")
1321 | |             value = cookie.get("value")
1322 | |             if not isinstance(name, str) or value is None:
1323 | |                 continue
1324 | |
1325 | |             try:
1326 | |                 cast(Any, self.api_manager._requests_session.cookies).set(
1327 | |                     name,
1328 | |                     value,
1329 | |                     domain=cookie.get("domain"),
1330 | |                     path=cookie.get("path", "/"),
1331 | |                 )
1332 | |                 synced_count += 1
1333 | |             except Exception:
1334 | |                 continue  # Skip problematic cookies silently
1335 | |
1336 | |         return synced_count
1337 | |
1338 | |     def check_js_errors(self) -> list[dict[str, Any]]:
1339 | |         """
1340 | |         Check for JavaScript errors in the browser console.
1341 | |
1342 | |         Returns:
1343 | |             list[Dict]: List of JavaScript errors found since last check
1344 | |         """
1345 | |         driver = self.driver
1346 | |         if not driver or not self.driver_live:
1347 | |             return []
1348 | |
1349 | |         try:
1350 | |             # Get browser logs (if available)
1351 | |             if hasattr(driver, 'get_log'):
1352 | |                 log_driver = cast(SupportsBrowserConsoleLogs, driver)
1353 | |                 logs = log_driver.get_log('browser')
1354 | |             else:
1355 | |                 logger.debug("WebDriver does not support get_log method")
1356 | |                 return []
1357 | |
1358 | |             # Filter for errors that occurred after last check
1359 | |             current_time = datetime.now(timezone.utc)
1360 | |             js_errors: list[dict[str, Any]] = []
1361 | |
1362 | |             for log_entry in logs:
1363 | |                 # Check if this is a JavaScript error
1364 | |                 if log_entry.get('level') in {'SEVERE', 'ERROR'}:
1365 | |                     # Parse timestamp (browser logs use milliseconds since epoch)
1366 | |                     log_timestamp = datetime.fromtimestamp(
1367 | |                         log_entry.get('timestamp', 0) / 1000,
1368 | |                         tz=timezone.utc
1369 | |                     )
1370 | |
1371 | |                     # Only include errors since last check
1372 | |                     if log_timestamp > self.last_js_error_check:
1373 | |                         js_errors.append({
1374 | |                             'timestamp': log_timestamp,
1375 | |                             'level': log_entry.get('level'),
1376 | |                             'message': log_entry.get('message', ''),
1377 | |                             'source': log_entry.get('source', '')
1378 | |                         })
1379 | |
1380 | |             # Update last check time
1381 | |             self.last_js_error_check = current_time
1382 | |
1383 | |             if js_errors:
1384 | |                 logger.warning(f"Found {len(js_errors)} JavaScript errors since last check")
1385 | |                 for error in js_errors:
1386 | |                     logger.debug(f"JS Error: {error['message']}")
1387 | |
1388 | |             return js_errors
1389 | |
1390 | |         except Exception as e:
1391 | |             logger.error(f"Failed to check JavaScript errors: {e}")
1392 | |             return []
1393 | |
1394 | |     def monitor_js_errors(self) -> bool:
1395 | |         """
1396 | |         Monitor JavaScript errors and log warnings if found.
1397 | |
1398 | |         Returns:
1399 | |             bool: True if no critical errors found, False if critical errors detected
1400 | |         """
1401 | |         errors = self.check_js_errors()
1402 | |
1403 | |         # Count critical errors (those that might affect functionality)
1404 | |         critical_errors = [
1405 | |             error for error in errors
1406 | |             if any(keyword in error['message'].lower() for keyword in [
1407 | |                 'uncaught', 'reference error', 'type error', 'syntax error'
1408 | |             ])
1409 | |         ]
1410 | |
1411 | |         if critical_errors:
1412 | |             logger.warning(f"Found {len(critical_errors)} critical JavaScript errors")
1413 | |             return False
1414 | |
1415 | |         return True
1416 | |
1417 | |     def restart_sess(self, url: Optional[str] = None) -> bool:
1418 | |         """
1419 | |         Restart the session.
1420 | |
1421 | |         Args:
1422 | |             url: Optional URL to navigate to after restart
1423 | |
1424 | |         Returns:
1425 | |             bool: True if restart successful, False otherwise
1426 | |         """
1427 | |         logger.info("Restarting session...")
1428 | |
1429 | |         # Close current session
1430 | |         self.close_sess(keep_db=True)
1431 | |
1432 | |         # Start new session
1433 | |         if not self.start_sess("Session Restart"):
1434 | |             logger.error("Failed to start session during restart.")
1435 | |             return False
1436 | |
1437 | |         # Ensure session is ready
1438 | |         if not self.ensure_session_ready("Session Restart"):
1439 | |             logger.error("Failed to ensure session ready during restart.")
1440 | |             self.close_sess(keep_db=True)
1441 | |             return False  # Navigate to URL if provided
1442 | |         if url and self.browser_manager.driver:
1443 | |             logger.info(f"Navigating to: {url}")
1444 | |             try:
1445 | |                 from utils import nav_to_page
1446 | |
1447 | |                 nav_success = nav_to_page(
1448 | |                     self.browser_manager.driver,
1449 | |                     url,
1450 | |                     selector="body",
1451 | |                     session_manager=self,
1452 | |                 )
1453 | |                 if not nav_success:
1454 | |                     logger.warning(f"Failed to navigate to {url} after restart.")
1455 | |                 else:
1456 | |                     logger.info(f"Successfully navigated to {url}.")
1457 | |             except Exception as e:
1458 | |                 logger.warning(f"Error navigating to {url} after restart: {e}")
1459 | |
1460 | |         self._record_session_refresh_metric("browser_error")
1461 | |         logger.info("Session restart completed successfully.")
1462 | |         return True
1463 | |
1464 | |     def check_browser_health(self) -> bool:
1465 | |         """Check browser health and detect browser death."""
1466 | |         current_time = time.time()
1467 | |         self.session_health_monitor['last_browser_health_check'] = current_time
1468 | |
1469 | |         # Check if browser is needed
1470 | |         if not self.browser_manager.browser_needed:
1471 | |             return True
1472 | |
1473 | |         # Check if driver exists and is responsive
1474 | |         if not self.browser_manager.is_session_valid():
1475 | |             self.session_health_monitor['browser_death_count'] = self.session_health_monitor.get('browser_death_count', 0) + 1
1476 | |             logger.warning(f"ðŸš¨ Browser death detected (count: {self.session_health_monitor['browser_death_count']})")
1477 | |             return False
1478 | |
1479 | |         return True
1480 | |
1481 | |     def attempt_browser_recovery(self, action_name: Optional[str] = None) -> bool:
1482 | |         """
1483 | |         Public method to attempt browser session recovery.
1484 | |
1485 | |         Args:
1486 | |             action_name: Optional name of the action for logging context
1487 | |
1488 | |         Returns:
1489 | |             bool: True if recovery successful, False otherwise
1490 | |         """
1491 | |         if action_name:
1492 | |             logger.info(f"Attempting browser recovery for: {action_name}")
1493 | |         return self._attempt_session_recovery(reason="browser_error")
1494 | |
1495 | |     def validate_system_health(self, action_name: str = "Unknown") -> bool:
1496 | |         """
1497 | |         Comprehensive system health validation before starting operations.
1498 | |         Consolidates health check patterns from Actions 6, 7, 8.
1499 | |
1500 | |         Args:
1501 | |             action_name: Name of the action performing the check
1502 | |
1503 | |         Returns:
1504 | |             True if system is healthy and ready for operations, False otherwise
1505 | |         """
1506 | |         try:
1507 | |             # Check 1: Session death cascade detection
1508 | |             if self.should_halt_operations():
1509 | |                 cascade_count = self.session_health_monitor.get('death_cascade_count', 0)
1510 | |                 logger.critical(
1511 | |                     f"ðŸš¨ {action_name}: Session death cascade detected (#{cascade_count}). "
1512 | |                     f"System is not safe for operations."
1513 | |                 )
1514 | |                 return False
1515 | |
1516 | |             # Check 2: Database connectivity
1517 | |             try:
1518 | |                 with self.get_db_conn_context() as db_session:
1519 | |                     if not db_session:
1520 | |                         logger.critical(f"ðŸš¨ {action_name}: Failed to get database session")
1521 | |                         return False
1522 | |
1523 | |                     # Test database connectivity with timeout
1524 | |                     from sqlalchemy import text
1525 | |                     result = db_session.execute(text("SELECT 1")).scalar()
1526 | |                     if result != 1:
1527 | |                         logger.critical(f"ðŸš¨ {action_name}: Database query returned unexpected result")
1528 | |                         return False
1529 | |
1530 | |             except Exception as db_err:
1531 | |                 logger.critical(f"ðŸš¨ {action_name}: Database connectivity error: {db_err}")
1532 | |                 return False
1533 | |
1534 | |             # Check 3: Browser session validity (if available)
1535 | |             try:
1536 | |                 if hasattr(self, 'is_sess_valid') and not self.is_sess_valid():
1537 | |                     logger.warning(f"âš ï¸ {action_name}: Browser session invalid - may affect operations")
1538 | |                     # Don't fail hard on browser issues for API-only operations
1539 | |
1540 | |             except Exception as browser_check_err:
1541 | |                 logger.debug(f"{action_name}: Browser health check failed (non-critical): {browser_check_err}")
1542 | |
1543 | |             logger.debug(f"âœ… {action_name}: System health check passed - all components validated")
1544 | |             return True
1545 | |
1546 | |         except Exception as health_err:
1547 | |             logger.critical(f"ðŸš¨ {action_name}: System health validation failed: {health_err}")
1548 | |             return False
1549 | |
1550 | |     def check_cascade_before_operation(self, action_name: str, operation_name: str) -> None:
1551 | |         """
1552 | |         Check for session death cascade before starting an operation.
1553 | |
1554 | |         Args:
1555 | |             action_name: Name of the action performing the check
1556 | |             operation_name: Name of the operation about to be performed
1557 | |
1558 | |         Raises:
1559 | |             Exception: If cascade detected
1560 | |         """
1561 | |         if self.should_halt_operations():
1562 | |             cascade_count = self.session_health_monitor.get('death_cascade_count', 0)
1563 | |             logger.critical(
1564 | |                 f"ðŸš¨ {action_name}: CASCADE DETECTED before {operation_name}: "
1565 | |                 f"Session death cascade #{cascade_count} - halting operation"
1566 | |             )
1567 | |             raise Exception(
1568 | |                 f"Session death cascade detected before {operation_name} (#{cascade_count})"
1569 | |             )
1570 | |
1571 | |     def close_sess(self, keep_db: bool = False):
1572 | |         """
1573 | |         Close the session.
1574 | |
1575 | |         Args:
1576 | |             keep_db: If True, keeps database connections alive
1577 | |         """
1578 | |         logger.debug(f"Closing session (keep_db={keep_db})")
1579 | |
1580 | |         # Close browser
1581 | |         self.close_browser()
1582 | |
1583 | |         # Close database connections if requested
1584 | |         if not keep_db:
1585 | |             self.db_manager.close_connections(dispose_engine=True)
1586 | |
1587 | |         # Clear API identifiers
1588 | |         self.api_manager.clear_identifiers()
1589 | |
1590 | |         # Reset session state
1591 | |         self.session_start_time = None
1592 | |         self._transition_state(SessionLifecycleState.UNINITIALIZED, "Session fully closed")
1593 | |         self._update_session_metrics(force_zero=True)
1594 | |
1595 | |         self._shutdown_metrics_exporter()
1596 | |
1597 | |         logger.debug("Session closed.")
1598 | |
1599 | |     def _cleanup_browser(self) -> None:
1600 | |         """Kill browser process and release resources."""
1601 | |         if not (self.browser_manager and self.driver_live):
1602 | |             return
1603 | |
1604 | |         # Try graceful quit first
1605 | |         try:
1606 | |             driver = self.driver
1607 | |             if driver:
1608 | |                 driver.quit()
1609 | |         except Exception as e:
1610 | |             logger.warning(f"Graceful browser quit failed: {e}")
1611 | |
1612 | |         # Force browser manager to release resources
1613 | |         try:
1614 | |             self.browser_manager.close_browser()
1615 | |         except Exception as e:
1616 | |             logger.warning(f"BrowserManager cleanup failed: {e}")
1617 | |
1618 | |         self._reset_cookie_sync_state("cleanup_browser")
1619 | |
1620 | |     def _cleanup_database(self) -> None:
1621 | |         """Close all database connections."""
1622 | |         if not self.db_manager:
1623 | |             return
1624 | |
1625 | |         try:
1626 | |             self.db_manager.close_connections(dispose_engine=True)
1627 | |         except Exception as e:
1628 | |             logger.warning(f"Database cleanup failed: {e}")
1629 | |
1630 | |     def _cleanup_api_caches(self) -> None:
1631 | |         """Clear API manager caches and CSRF token."""
1632 | |         if self.api_manager:
1633 | |             try:
1634 | |                 self.api_manager.clear_identifiers()
1635 | |             except Exception as e:
1636 | |                 logger.warning(f"API manager cleanup failed: {e}")
1637 | |
1638 | |         try:
1639 | |             self.invalidate_csrf_cache()
1640 | |         except Exception as e:
1641 | |             logger.warning(f"CSRF cache invalidation failed: {e}")
1642 | |
1643 | |     def _reset_session_state(self) -> None:
1644 | |         """Reset internal session state flags."""
1645 | |         self.session_start_time = None
1646 | |         self._db_init_attempted = False
1647 | |         self._transition_state(SessionLifecycleState.UNINITIALIZED, "Session state reset")
1648 | |         self._db_ready = False
1649 | |         self._update_session_metrics(force_zero=True)
1650 | |
1651 | |     def _force_session_restart(self, reason: str = "Watchdog timeout") -> bool:
1652 | |         """
1653 | |         Emergency session restart triggered by watchdog timeout.
1654 | |
1655 | |         Purpose:
1656 | |         --------
1657 | |         Forcefully restarts session when an operation hangs beyond timeout threshold.
1658 | |         More aggressive than close_sess() - kills browser process and clears all caches.
1659 | |
1660 | |         Args:
1661 | |             reason: Description of why restart was triggered (for logging)
1662 | |
1663 | |         Returns:
1664 | |             bool: Always returns False (operation failed, restart attempted)
1665 | |
1666 | |         Called By:
1667 | |         ----------
1668 | |         APICallWatchdog when operation exceeds timeout_seconds threshold
1669 | |
1670 | |         Actions Taken:
1671 | |         --------------
1672 | |         1. Log critical timeout event with reason
1673 | |         2. Kill browser process (if running)
1674 | |         3. Close all database connections
1675 | |         4. Clear API manager caches (identifiers, CSRF token)
1676 | |         5. Clear CSRF cache
1677 | |         6. Set session_ready=False
1678 | |         7. Log restart completion
1679 | |
1680 | |         Example:
1681 | |         --------
1682 | |         >>> watchdog = APICallWatchdog(timeout_seconds=120)
1683 | |         >>> watchdog.start("relationship_prob",
1684 | |         ...               lambda: session_manager._force_session_restart("API timeout"))
1685 | |         """
1686 | |         logger.critical(
1687 | |             f"ðŸš¨ FORCE SESSION RESTART triggered: {reason} - "
1688 | |             "killing browser and clearing caches"
1689 | |         )
1690 | |
1691 | |         try:
1692 | |             self._cleanup_browser()
1693 | |             self._cleanup_database()
1694 | |             self._cleanup_api_caches()
1695 | |             self._reset_session_state()
1696 | |             self._record_session_refresh_metric("api_forced")
1697 | |             self._shutdown_metrics_exporter()
1698 | |
1699 | |             logger.info("Force session restart complete - session marked invalid")
1700 | |
1701 | |         except Exception as e:
1702 | |             logger.error(f"Error during force session restart: {e}", exc_info=True)
1703 | |
1704 | |         # Always return False - operation failed, restart attempted
1705 | |         return False
1706 | |
1707 | |     # === MISSING API METHODS FROM OLD SESSIONMANAGER ===
1708 | |
1709 | |     @api_retry()
1710 | |     def get_csrf(self) -> Optional[str]:
1711 | |         """
1712 | |         Retrieve CSRF token from API.
1713 | |
1714 | |         Returns:
1715 | |             str: CSRF token if successful, None otherwise
1716 | |         """
1717 | |         if not self.is_sess_valid():
1718 | |             logger.error("get_csrf: Session invalid.")
1719 | |             return None
1720 | |
1721 | |         from urllib.parse import urljoin
1722 | |         csrf_token_url = urljoin(config_schema.api.base_url, "discoveryui-matches/parents/api/csrfToken")
1723 | |         logger.debug(f"Attempting to fetch fresh CSRF token from: {csrf_token_url}")
1724 | |
1725 | |         # Check essential cookies
1726 | |         essential_cookies = list(self.ESSENTIAL_SESSION_COOKIES)
1727 | |         if not self.get_cookies(essential_cookies, timeout=10):
1728 | |             logger.warning(f"Essential cookies {essential_cookies} NOT found before CSRF token API call.")
1729 | |
1730 | |         try:
1731 | |             api_request = self._get_utils_attr("_api_req")
1732 | |
1733 | |             response_data = api_request(
1734 | |                 url=csrf_token_url,
1735 | |                 driver=self.driver,
1736 | |                 session_manager=self,
1737 | |                 method="GET",
1738 | |                 use_csrf_token=False,
1739 | |                 api_description="CSRF Token API",
1740 | |                 force_text_response=True,
1741 | |             )
1742 | |
1743 | |             if response_data and isinstance(response_data, str):
1744 | |                 csrf_token_val = response_data.strip()
1745 | |                 if csrf_token_val and len(csrf_token_val) > 20:
1746 | |                     logger.debug(f"CSRF token successfully retrieved (Length: {len(csrf_token_val)}).")
1747 | |                     self.api_manager.csrf_token = csrf_token_val
1748 | |                     return csrf_token_val
1749 | |                 logger.error(f"CSRF token API returned empty or invalid string: '{csrf_token_val}'")
1750 | |                 return None
1751 | |             logger.warning("Failed to get CSRF token response via _api_req.")
1752 | |             return None
1753 | |
1754 | |         except Exception as e:
1755 | |             logger.error(f"Unexpected error in get_csrf: {e}", exc_info=True)
1756 | |             return None
1757 | |
1758 | |     @api_retry()
1759 | |     def get_my_profile_id(self) -> Optional[str]:
1760 | |         """
1761 | |         Retrieve user's profile ID (ucdmid).
1762 | |
1763 | |         Returns:
1764 | |             str: Profile ID if successful, None otherwise
1765 | |         """
1766 | |         if not self.is_sess_valid():
1767 | |             logger.error("get_my_profile_id: Session invalid.")
1768 | |             return None
1769 | |
1770 | |         from urllib.parse import urljoin
1771 | |         url = urljoin(config_schema.api.base_url, "app-api/cdp-p13n/api/v1/users/me?attributes=ucdmid")
1772 | |         logger.debug("Attempting to fetch own profile ID (ucdmid)...")
1773 | |
1774 | |         try:
1775 | |             api_request = self._get_utils_attr("_api_req")
1776 | |
1777 | |             response_data = api_request(
1778 | |                 url=url,
1779 | |                 driver=self.driver,
1780 | |                 session_manager=self,
1781 | |                 method="GET",
1782 | |                 use_csrf_token=False,
1783 | |                 api_description="Get my profile_id",
1784 | |             )
1785 | |
1786 | |             if not response_data:
1787 | |                 logger.warning("Failed to get profile_id response via _api_req.")
1788 | |                 return None
1789 | |
1790 | |             if isinstance(response_data, dict) and "data" in response_data:
1791 | |                 data_dict = response_data["data"]
1792 | |                 if isinstance(data_dict, dict) and "ucdmid" in data_dict:
1793 | |                     my_profile_id_val = str(data_dict["ucdmid"]).upper()
1794 | |                     logger.debug(f"Successfully retrieved profile_id: {my_profile_id_val}")
1795 | |                     # Store in API manager
1796 | |                     self.api_manager.my_profile_id = my_profile_id_val
1797 | |                     if not self._profile_id_logged:
1798 | |                         logger.info(f"My profile id: {my_profile_id_val}")
1799 | |                         self._profile_id_logged = True
1800 | |                     return my_profile_id_val
1801 | |                 logger.error("Could not find 'ucdmid' in 'data' dict of profile_id API response.")
1802 | |                 return None
1803 | |             logger.error(f"Unexpected response format for profile_id API: {type(response_data)}")
1804 | |             return None
1805 | |
1806 | |         except Exception as e:
1807 | |             logger.error(f"Unexpected error in get_my_profile_id: {e}", exc_info=True)
1808 | |             return None
1809 | |
1810 | |     @api_retry()
1811 | |     def get_my_uuid(self) -> Optional[str]:
1812 | |         """
1813 | |         Retrieve user's UUID (testId).
1814 | |
1815 | |         Returns:
1816 | |             str: UUID if successful, None otherwise
1817 | |         """
1818 | |         if not self.is_sess_valid():
1819 | |             # Reduce log spam during shutdown - only log once per minute
1820 | |             if not hasattr(self, '_last_uuid_error_time') or time.time() - self._last_uuid_error_time > 60:
1821 | |                 logger.error("get_my_uuid: Session invalid.")
1822 | |                 self._last_uuid_error_time = time.time()
1823 | |             return None
1824 | |
1825 | |         from urllib.parse import urljoin
1826 | |         url = urljoin(config_schema.api.base_url, API_PATH_UUID_NAVHEADER)
1827 | |         logger.debug("Attempting to fetch own UUID (testId) from header/dna API...")
1828 | |
1829 | |         try:
1830 | |             api_request = self._get_utils_attr("_api_req")
1831 | |
1832 | |             response_data = api_request(
1833 | |                 url=url,
1834 | |                 driver=self.driver,
1835 | |                 session_manager=self,
1836 | |                 method="GET",
1837 | |                 use_csrf_token=False,
1838 | |                 api_description="Get UUID API",
1839 | |             )
1840 | |
1841 | |             if response_data and isinstance(response_data, dict):
1842 | |                 if "testId" in response_data:
1843 | |                     my_uuid_val = str(response_data["testId"]).upper()
1844 | |                     logger.debug(f"Successfully retrieved UUID: {my_uuid_val}")
1845 | |                     # Store in API manager
1846 | |                     self.api_manager.my_uuid = my_uuid_val
1847 | |                     if not self._uuid_logged:
1848 | |                         logger.debug(f"My uuid: {my_uuid_val}")
1849 | |                         self._uuid_logged = True
1850 | |                     return my_uuid_val
1851 | |                 logger.error("Could not retrieve UUID ('testId' missing in response).")
1852 | |                 return None
1853 | |             logger.error("Failed to get header/dna data via _api_req.")
1854 | |             return None
1855 | |
1856 | |         except Exception as e:
1857 | |             logger.error(f"Unexpected error in get_my_uuid: {e}", exc_info=True)
1858 | |             return None
1859 | |
1860 | |     @api_retry()
1861 | |     def get_my_tree_id(self) -> Optional[str]:
1862 | |         """
1863 | |         Retrieve user's tree ID.
1864 | |
1865 | |         Returns:
1866 | |             str: Tree ID if successful, None otherwise
1867 | |         """
1868 | |         try:
1869 | |             import api_utils as local_api_utils
1870 | |         except ImportError as e:
1871 | |             logger.error(f"get_my_tree_id: Failed to import api_utils: {e}")
1872 | |             raise ImportError(f"api_utils module failed to import: {e}") from e
1873 | |
1874 | |         tree_name_config = config_schema.api.tree_name
1875 | |         if not tree_name_config:
1876 | |             logger.debug("TREE_NAME not configured, skipping tree ID retrieval.")
1877 | |             return None
1878 | |
1879 | |         if not self.is_sess_valid():
1880 | |             logger.error("get_my_tree_id: Session invalid.")
1881 | |             return None
1882 | |
1883 | |         logger.debug(f"Delegating tree ID fetch for TREE_NAME='{tree_name_config}' to api_utils...")
1884 | |         try:
1885 | |             my_tree_id_val = local_api_utils.call_header_trees_api_for_tree_id(
1886 | |                 self, tree_name_config
1887 | |             )
1888 | |             if my_tree_id_val:
1889 | |                 # Store in API manager
1890 | |                 self.api_manager.my_tree_id = my_tree_id_val
1891 | |                 if not self._tree_id_logged:
1892 | |                     logger.debug(f"My tree id: {my_tree_id_val}")
1893 | |                     self._tree_id_logged = True
1894 | |                 return my_tree_id_val
1895 | |             logger.warning("api_utils.call_header_trees_api_for_tree_id returned None.")
1896 | |             return None
1897 | |         except Exception as e:
1898 | |             logger.error(f"Error calling api_utils.call_header_trees_api_for_tree_id: {e}", exc_info=True)
1899 | |             return None
1900 | |
1901 | |     @api_retry()
1902 | |     def get_tree_owner(self, tree_id: Optional[str]) -> Optional[str]:
1903 | |         """
1904 | |         Retrieve tree owner name.
1905 | |
1906 | |         Args:
1907 | |             tree_id: The tree ID to get owner for
1908 | |
1909 | |         Returns:
1910 | |             str: Tree owner name if successful, None otherwise
1911 | |         """
1912 | |         try:
1913 | |             import api_utils as local_api_utils
1914 | |         except ImportError as e:
1915 | |             logger.error(f"get_tree_owner: Failed to import api_utils: {e}")
1916 | |             raise ImportError(f"api_utils module failed to import: {e}") from e
1917 | |
1918 | |         if not tree_id:
1919 | |             logger.warning("Cannot get tree owner: tree_id is missing.")
1920 | |             return None
1921 | |
1922 | |         if not self.is_sess_valid():
1923 | |             logger.error("get_tree_owner: Session invalid.")
1924 | |             return None
1925 | |
1926 | |         logger.debug(f"Delegating tree owner fetch for tree ID {tree_id} to api_utils...")
1927 | |         try:
1928 | |             owner_name = local_api_utils.call_tree_owner_api(self, tree_id)
1929 | |             if owner_name:
1930 | |                 # Store in API manager (logging done separately in main.py startup)
1931 | |                 self.api_manager.tree_owner_name = owner_name
1932 | |                 return owner_name
1933 | |             logger.warning("api_utils.call_tree_owner_api returned None.")
1934 | |             return None
1935 | |         except Exception as e:
1936 | |             logger.error(f"Error calling api_utils.call_tree_owner_api: {e}", exc_info=True)
1937 | |             return None
1938 | |
1939 | |     # Database delegation methods
1940 | |     def get_db_conn(self) -> Any:
1941 | |         """Get a database session."""
1942 | |         return self.db_manager.get_session()
1943 | |
1944 | |     def return_session(self, session: Any) -> None:
1945 | |         """Return a database session."""
1946 | |         self.db_manager.return_session(session)
1947 | |
1948 | |     def get_db_conn_context(self) -> Any:
1949 | |         """Get database session context manager."""
1950 | |         return self.db_manager.get_session_context()
1951 | |
1952 | |     def cls_db_conn(self, keep_db: bool = True) -> None:
1953 | |         """Close database connections."""
1954 | |         self.db_manager.close_connections(
1955 | |             dispose_engine=not keep_db
1956 | |         )  # Browser delegation methods
1957 | |
1958 | |     def invalidate_csrf_cache(self) -> None:
1959 | |         """Invalidate cached CSRF token (useful on auth errors)."""
1960 | |         self._cached_csrf_token = None
1961 | |         self._csrf_cache_time = 0
1962 | |
1963 | |     @property
1964 | |     def driver(self) -> Optional[WebDriverType]:
1965 | |         """Get the WebDriver instance."""
1966 | |         return self.browser_manager.driver
1967 | |
1968 | |     @property
1969 | |     def driver_live(self) -> bool:
1970 | |         """Check if driver is live."""
1971 | |         return self.browser_manager.driver_live
1972 | |
1973 | |     def make_tab(self) -> Optional[str]:
1974 | |         """Create a new browser tab."""
1975 | |         return self.browser_manager.create_new_tab()
1976 | |
1977 | |     # API delegation methods
1978 | |     @property
1979 | |     def my_profile_id(self) -> Optional[str]:
1980 | |         """Get the user's profile ID."""
1981 | |         # Try to get from API manager first, then retrieve if needed
1982 | |         profile_id = self.api_manager.my_profile_id
1983 | |         if not profile_id:
1984 | |             profile_id = self.get_my_profile_id()
1985 | |         return profile_id
1986 | |
1987 | |     @property
1988 | |     def my_uuid(self) -> Optional[str]:
1989 | |         """Get the user's UUID."""
1990 | |         # Try to get from API manager first, then retrieve if needed
1991 | |         uuid_val = self.api_manager.my_uuid
1992 | |         if not uuid_val:
1993 | |             uuid_val = self.get_my_uuid()
1994 | |         return uuid_val
1995 | |
1996 | |     @property
1997 | |     def my_tree_id(self) -> Optional[str]:
1998 | |         """Get the user's tree ID."""
1999 | |         # Try to get from API manager first, then retrieve if needed
2000 | |         tree_id = self.api_manager.my_tree_id
2001 | |         if not tree_id and config_schema.api.tree_name:
2002 | |             tree_id = self.get_my_tree_id()
2003 | |         return tree_id
2004 | |
2005 | |     @property
2006 | |     def csrf_token(self) -> Optional[str]:
2007 | |         """Get the CSRF token with smart caching."""
2008 | |         # âš¡ OPTIMIZATION 1: Check pre-cached CSRF token first
2009 | |         if self._cached_csrf_token and self._csrf_cache_time:
2010 | |             cache_age = time.time() - self._csrf_cache_time
2011 | |             if cache_age < self._csrf_cache_duration:
2012 | |                 return self._cached_csrf_token
2013 | |
2014 | |         # Return cached token from API manager if available
2015 | |         return self.api_manager.csrf_token
2016 | |
2017 | |     def _precache_csrf_token(self) -> None:
2018 | |         """
2019 | |         âš¡ OPTIMIZATION 1: Pre-cache CSRF token during session setup to eliminate delays
2020 | |         during Action 6 API operations.
2021 | |         """
2022 | |         try:
2023 | |             if not self.browser_manager or not self.browser_manager.driver:
2024 | |                 logger.debug("âš¡ CSRF pre-cache: Browser not available, skipping")
2025 | |                 return
2026 | |
2027 | |             # Try to get CSRF token from cookies
2028 | |             driver = cast(Any, self.browser_manager.driver)
2029 | |             csrf_cookie_names = ['_dnamatches-matchlistui-x-csrf-token', '_csrf']
2030 | |
2031 | |             driver_cookies_list = cast(list[dict[str, Any]], driver.get_cookies())
2032 | |             driver_cookies_dict = {
2033 | |                 c["name"]: c["value"]
2034 | |                 for c in driver_cookies_list
2035 | |                 if isinstance(c, dict) and "name" in c and "value" in c
2036 | |             }
2037 | |
2038 | |             for name in csrf_cookie_names:
2039 | |                 if driver_cookies_dict.get(name):
2040 | |                     from urllib.parse import unquote
2041 | |                     csrf_token_val = unquote(driver_cookies_dict[name]).split("|")[0]
2042 | |
2043 | |                     # Cache the token
2044 | |                     self._cached_csrf_token = csrf_token_val
2045 | |                     self._csrf_cache_time = time.time()
2046 | |
2047 | |                     logger.debug(f"âš¡ Pre-cached CSRF token '{name}' during session setup (performance optimization)")
2048 | |                     return
2049 | |
2050 | |             logger.debug("âš¡ CSRF pre-cache: No CSRF tokens found in cookies yet")
2051 | |
2052 | |         except Exception as e:
2053 | |             logger.debug(f"âš¡ CSRF pre-cache: Error pre-caching CSRF token: {e}")
2054 | |
2055 | |     def _is_csrf_token_valid(self) -> bool:
2056 | |         """
2057 | |         âš¡ OPTIMIZATION 1: Check if cached CSRF token is still valid.
2058 | |         """
2059 | |         if not self._cached_csrf_token or not self._csrf_cache_time:
2060 | |             return False
2061 | |
2062 | |         cache_age = time.time() - self._csrf_cache_time
2063 | |         return cache_age < self._csrf_cache_duration
2064 | |
2065 | |     def is_csrf_token_valid(self) -> bool:
2066 | |         """Typed public helper for callers that need to verify CSRF freshness."""
2067 | |
2068 | |         return self._is_csrf_token_valid()
2069 | |
2070 | |     # Public properties
2071 | |     @property
2072 | |     def tree_owner_name(self) -> Optional[str]:
2073 | |         """Get the tree owner name."""
2074 | |         return self.api_manager.tree_owner_name
2075 | |
2076 | |     @property
2077 | |     def requests_session(self) -> requests.Session:
2078 | |         """Get the requests session."""
2079 | |         return self.api_manager.requests_session
2080 | |
2081 | |     # Enhanced capabilities properties
2082 | |     @property
2083 | |     def scraper(self) -> Optional[Any]:
2084 | |         """Get the CloudScraper instance for anti-bot protection."""
2085 | |         return getattr(self, "_scraper", None)
2086 | |
2087 | |     @scraper.setter
2088 | |     def scraper(self, value: Any) -> None:
2089 | |         """Set the CloudScraper instance."""
2090 | |         self._scraper = value
2091 | |
2092 | |     # Compatibility properties for legacy code
2093 | |     @property
2094 | |     def browser_needed(self) -> bool:
2095 | |         """Get/set browser needed flag."""
2096 | |         return self.browser_manager.browser_needed
2097 | |
2098 | |     @browser_needed.setter
2099 | |     def browser_needed(self, value: bool) -> None:
2100 | |         """Set browser needed flag."""
2101 | |         self.browser_manager.browser_needed = value
2102 | |
2103 | |     @property
2104 | |     def _requests_session(self) -> requests.Session:
2105 | |         """Compatibility accessor for the API requests session."""
2106 | |         return self.api_manager.requests_session
2107 | |
2108 | |     # Status properties
2109 | |     @property
2110 | |     def is_ready(self) -> bool:
2111 | |         """Check if the session manager is ready for work."""
2112 | |         db_ready = self.db_manager.is_ready
2113 | |         browser_ready = (
2114 | |             not self.browser_manager.browser_needed or self.browser_manager.driver_live
2115 | |         )
2116 | |         api_ready = self.api_manager.has_essential_identifiers
2117 | |         return db_ready and browser_ready and api_ready
2118 | |
2119 | |     @property
2120 | |     def session_age_seconds(self) -> Optional[float]:
2121 | |         """Get the age of the current session in seconds."""
2122 | |         if self.session_start_time:
2123 | |             return time.time() - self.session_start_time
2124 | |         return None
2125 | |
2126 | |     def _update_session_metrics(self, force_zero: bool = False) -> None:
2127 | |         """Update Prometheus session uptime gauge."""
2128 | |         try:
2129 | |             if force_zero:
2130 | |                 metrics().session_uptime.set(0.0)
2131 | |                 return
2132 | |
2133 | |             session_age = self.session_age_seconds
2134 | |             metrics().session_uptime.set(float(session_age) if session_age is not None else 0.0)
2135 | |         except Exception:
2136 | |             logger.debug("Failed to update session uptime metric", exc_info=True)
2137 | |
2138 | |     @staticmethod
2139 | |     def _record_session_refresh_metric(reason: str) -> None:
2140 | |         """Increment session refresh counter for a specific reason."""
2141 | |         try:
2142 | |             safe_reason = reason or "unknown"
2143 | |             metrics().session_refresh.inc(safe_reason)
2144 | |         except Exception:
2145 | |             logger.debug("Failed to record session refresh metric", exc_info=True)
2146 | |
2147 | |     def _ensure_metrics_exporter(self) -> None:
2148 | |         """Start Prometheus metrics exporter when metrics are enabled."""
2149 | |         if getattr(self, "_metrics_exporter_started", False):
2150 | |             return
2151 | |
2152 | |         observability_cfg = getattr(config_schema, "observability", None)
2153 | |         if not observability_cfg or not getattr(observability_cfg, "enable_prometheus_metrics", False):
2154 | |             return
2155 | |
2156 | |         try:
2157 | |             if start_metrics_exporter(
2158 | |                 observability_cfg.metrics_export_host,
2159 | |                 observability_cfg.metrics_export_port,
2160 | |             ):
2161 | |                 self._metrics_exporter_started = True
2162 | |         except Exception:
2163 | |             logger.debug("Failed to start Prometheus metrics exporter", exc_info=True)
2164 | |
2165 | |     def _shutdown_metrics_exporter(self) -> None:
2166 | |         """Stop the metrics exporter if this manager started it."""
2167 | |         if not getattr(self, "_metrics_exporter_started", False):
2168 | |             return
2169 | |         try:
2170 | |             stop_metrics_exporter()
2171 | |         except Exception:
2172 | |             logger.debug("Failed to stop Prometheus metrics exporter", exc_info=True)
2173 | |         finally:
2174 | |             self._metrics_exporter_started = False
2175 | |
2176 | |     # PHASE 5.1: Session cache management methods
2177 | |     def get_session_performance_stats(self) -> dict[str, Any]:
2178 | |         """Get performance statistics for this session"""
2179 | |         stats = get_session_cache_stats()
2180 | |         stats.update(
2181 | |             {
2182 | |                 "session_ready": self.session_ready,
2183 | |                 "session_age": self.session_age_seconds,
2184 | |                 "last_readiness_check_age": (
2185 | |                     time.time() - self._last_readiness_check
2186 | |                     if self._last_readiness_check
2187 | |                     else None
2188 | |                 ),
2189 | |                 "db_ready": (
2190 | |                     self.db_manager.is_ready
2191 | |                     if hasattr(self.db_manager, "is_ready")
2192 | |                     else False
2193 | |                 ),
2194 | |                 "browser_needed": self.browser_manager.browser_needed,
2195 | |                 "driver_live": self.browser_manager.driver_live,
2196 | |             }
2197 | |         )
2198 | |         return stats
2199 | |
2200 | |     @classmethod
2201 | |     def clear_session_caches(cls) -> int:
2202 | |         """Clear all session caches for fresh initialization"""
2203 | |         return clear_session_cache()
     | |____________________________________^
     |

PLR0904 Too many public methods (29 > 20)
    --> health_monitor.py:131:1
     |
 131 | / class SessionHealthMonitor:
 132 | |     """
 133 | |     Comprehensive session health monitoring with predictive analytics.
 134 | |     """
 135 | |
 136 | |     _action6_callback_registered: bool
 137 | |
 138 | |     def __init__(self) -> None:
 139 | |         self.metrics_history: dict[str, deque[tuple[float, float]]] = {}
 140 | |         self.current_metrics: dict[str, HealthMetric] = {}
 141 | |         self.alerts: list[HealthAlert] = []
 142 | |         self.health_score_history: deque[tuple[float, float]] = deque(maxlen=100)
 143 | |         self.session_start_time = time.time()
 144 | |         self.last_health_check = time.time()
 145 | |         self.monitoring_active = False
 146 | |         self.lock = threading.Lock()
 147 | |
 148 | |         # Performance tracking
 149 | |         self.api_response_times: deque[float] = deque(maxlen=50)
 150 | |         self.error_counts: dict[str, int] = {}
 151 | |         self.page_processing_times: deque[float] = deque(maxlen=20)
 152 | |         self.memory_usage_history: deque[float] = deque(maxlen=30)
 153 | |
 154 | |         # Enhanced error rate monitoring - PERFORMANCE OPTIMIZED
 155 | |         self.error_timestamps: deque[float] = deque(maxlen=2000)  # Increased for 20+ hour sessions
 156 | |         self.error_rate_warnings_sent: dict[str, float] = {}  # Track when warnings were sent
 157 | |         self.last_error_rate_check: float = time.time()
 158 | |
 159 | |         # Metric alert de-duplication (prevents alert spam on repeated updates)
 160 | |         self._last_metric_alert_level: dict[str, AlertLevel] = {}
 161 | |         self._last_metric_alert_time: dict[str, float] = {}
 162 | |         self._metric_alert_cooldown_seconds: float = 60.0  # Only re-log after 60s unless level escalates
 163 | |
 164 | |         # Performance optimization for long sessions
 165 | |         self._monitoring_interval: float = 30.0  # Base monitoring interval
 166 | |         self._adaptive_interval: bool = True  # Enable adaptive monitoring
 167 | |         self._last_cleanup_time: float = time.time()
 168 | |         self._cleanup_interval: float = 300.0  # Clean up every 5 minutes
 169 | |
 170 | |         # Automatic intervention flags
 171 | |         self._emergency_halt_requested: bool = False
 172 | |         self._emergency_halt_reason: str = ""
 173 | |         self._emergency_halt_timestamp: float = 0.0
 174 | |         self._immediate_intervention_requested: bool = False
 175 | |         self._immediate_intervention_reason: str = ""
 176 | |         self._immediate_intervention_timestamp: float = 0.0
 177 | |         self._enhanced_monitoring_active: bool = False
 178 | |         self._enhanced_monitoring_reason: str = ""
 179 | |         self._enhanced_monitoring_timestamp: float = 0.0
 180 | |
 181 | |         # Predictive analytics
 182 | |         self.failure_patterns: list[dict[str, Any]] = []
 183 | |         self.success_patterns: list[dict[str, Any]] = []
 184 | |         # Safety test mode flag to standardize alert prefixes
 185 | |         self._safety_test_mode: bool = False
 186 | |         # Integration bookkeeping
 187 | |         self._action6_callback_registered: bool = False
 188 | |
 189 | |         # Initialize metrics
 190 | |         self._initialize_metrics()
 191 | |
 192 | |         logger.debug("Session Health Monitor initialized")
 193 | |
 194 | |     def _initialize_metrics(self) -> None:
 195 | |         """Initialize health metrics with workload-appropriate thresholds for 724-page processing."""
 196 | |         metrics_config = {
 197 | |             "api_response_time": {"warning": 15.0, "critical": 25.0, "weight": 2.0},  # OPTIMIZATION: Less pessimistic thresholds (wâ€¦
 198 | |             "memory_usage_mb": {"warning": 200.0, "critical": 400.0, "weight": 1.5},
 199 | |             "error_rate": {"warning": 10.0, "critical": 25.0, "weight": 3.0},  # WORKLOAD-APPROPRIATE: Errors per hour for 724-page â€¦
 200 | |             "session_age_minutes": {"warning": 600.0, "critical": 1200.0, "weight": 1.0},  # WORKLOAD-APPROPRIATE: 10-20 hours for 7â€¦
 201 | |             "browser_age_minutes": {"warning": 120.0, "critical": 180.0, "weight": 2.5},  # WORKLOAD-APPROPRIATE: 2-3 hours browser â€¦
 202 | |             "pages_since_refresh": {"warning": 50.0, "critical": 75.0, "weight": 2.0},  # WORKLOAD-APPROPRIATE: More pages before reâ€¦
 203 | |             "cpu_usage_percent": {"warning": 70.0, "critical": 90.0, "weight": 1.0},
 204 | |             "disk_usage_percent": {"warning": 85.0, "critical": 95.0, "weight": 0.5},
 205 | |         }
 206 | |
 207 | |         for name, config in metrics_config.items():
 208 | |             self.current_metrics[name] = HealthMetric(
 209 | |                 name=name,
 210 | |                 value=0.0,
 211 | |                 threshold_warning=config["warning"],
 212 | |                 threshold_critical=config["critical"],
 213 | |                 weight=config["weight"]
 214 | |             )
 215 | |             self.metrics_history[name] = deque(maxlen=100)
 216 | |
 217 | |     def begin_safety_test(self) -> None:
 218 | |         """Enable safety test mode to uniformly prefix all alerts and notices."""
 219 | |         self._safety_test_mode = True
 220 | |
 221 | |     def end_safety_test(self) -> None:
 222 | |         """Disable safety test mode."""
 223 | |         self._safety_test_mode = False
 224 | |
 225 | |     def _safety_prefix(self) -> str:
 226 | |         """Return the standard prefix for safety-test logs if enabled."""
 227 | |         return "ðŸ§ª [SAFETY TEST] " if self._safety_test_mode else ""
 228 | |
 229 | |     def update_metric(self, name: str, value: float):
 230 | |         """Update a specific health metric."""
 231 | |         with self.lock:
 232 | |             if name not in self.current_metrics:
 233 | |                 defaults = _DYNAMIC_METRIC_DEFAULTS.get(name)
 234 | |
 235 | |                 if defaults is None and name.startswith("api_") and name.endswith("_last_duration"):
 236 | |                     defaults = {"warning": 8.0, "critical": 15.0, "weight": 1.0}
 237 | |
 238 | |                 if defaults is not None:
 239 | |                     self.current_metrics[name] = HealthMetric(
 240 | |                         name=name,
 241 | |                         value=0.0,
 242 | |                         threshold_warning=defaults["warning"],
 243 | |                         threshold_critical=defaults["critical"],
 244 | |                         weight=defaults.get("weight", 1.0),
 245 | |                     )
 246 | |                     self.metrics_history[name] = deque(maxlen=100)
 247 | |                     logger.debug(f"Registered dynamic health metric: {name}")
 248 | |                 else:
 249 | |                     logger.debug(f"Ignoring update for unrecognized metric without defaults: {name}")
 250 | |                     return
 251 | |
 252 | |             metric = self.current_metrics[name]
 253 | |             metric.value = value
 254 | |             metric.timestamp = time.time()
 255 | |             self.metrics_history[name].append((time.time(), value))
 256 | |
 257 | |             # Check for alerts
 258 | |             self._check_metric_alerts(name)
 259 | |
 260 | |     def _check_metric_alerts(self, metric_name: str) -> None:
 261 | |         """Check if a metric triggers any alerts, with de-duplication and cooldown."""
 262 | |         metric = self.current_metrics[metric_name]
 263 | |
 264 | |         level: Optional[AlertLevel] = None
 265 | |         message: str = ""
 266 | |         threshold: float = 0.0
 267 | |
 268 | |         if metric.value >= metric.threshold_critical:
 269 | |             level = AlertLevel.CRITICAL
 270 | |             message = f"{metric_name} is critical: {metric.value:.2f} >= {metric.threshold_critical}"
 271 | |             threshold = metric.threshold_critical
 272 | |         elif metric.value >= metric.threshold_warning:
 273 | |             level = AlertLevel.WARNING
 274 | |             message = f"{metric_name} is elevated: {metric.value:.2f} >= {metric.threshold_warning}"
 275 | |             threshold = metric.threshold_warning
 276 | |
 277 | |         if level is None:
 278 | |             # Reset last level so future crossings log again
 279 | |             self._last_metric_alert_level.pop(metric_name, None)
 280 | |             return
 281 | |
 282 | |         # Gate logs: only log when escalating level or after cooldown
 283 | |         last_level = self._last_metric_alert_level.get(metric_name)
 284 | |         last_time = self._last_metric_alert_time.get(metric_name, 0.0)
 285 | |         now = time.time()
 286 | |
 287 | |         should_log = False
 288 | |         if last_level is None:
 289 | |             should_log = True
 290 | |         elif level.value != last_level.value:
 291 | |             # Escalation from WARNING->CRITICAL (or vice versa) should log
 292 | |             should_log = True
 293 | |         elif (now - last_time) >= self._metric_alert_cooldown_seconds:
 294 | |             should_log = True
 295 | |
 296 | |         if should_log:
 297 | |             self._create_alert(level, "session_health", message, metric_name, metric.value, threshold)
 298 | |             self._last_metric_alert_level[metric_name] = level
 299 | |             self._last_metric_alert_time[metric_name] = now
 300 | |
 301 | |     def _create_alert(self, level: AlertLevel, component: str, message: str,
 302 | |                      metric_name: str, metric_value: float, threshold: float):
 303 | |         """Create a new health alert."""
 304 | |         alert = HealthAlert(
 305 | |             level=level,
 306 | |             component=component,
 307 | |             message=message,
 308 | |             metric_name=metric_name,
 309 | |             metric_value=metric_value,
 310 | |             threshold=threshold
 311 | |         )
 312 | |
 313 | |         self.alerts.append(alert)
 314 | |
 315 | |         # Log alert with standardized safety test prefix when in test mode
 316 | |         test_prefix = self._safety_prefix()
 317 | |
 318 | |         if level == AlertLevel.CRITICAL:
 319 | |             logger.critical(f"{test_prefix}ðŸš¨ CRITICAL ALERT: {message}")
 320 | |         elif level == AlertLevel.WARNING:
 321 | |             logger.warning(f"{test_prefix}âš ï¸ WARNING: {message}")
 322 | |         else:
 323 | |             logger.info(f"{test_prefix}INFO: {message}")
 324 | |
 325 | |     def calculate_health_score(self) -> float:
 326 | |         """
 327 | |         Calculate overall health score (0-100) based on all metrics.
 328 | |
 329 | |         Returns:
 330 | |             Health score from 0 (critical) to 100 (excellent)
 331 | |         """
 332 | |         with self.lock:
 333 | |             total_score = 100.0
 334 | |             total_weight = 0.0
 335 | |
 336 | |             for metric in self.current_metrics.values():
 337 | |                 # Calculate metric score (0-100)
 338 | |                 if metric.value <= metric.threshold_warning * 0.5:
 339 | |                     metric_score = 100.0  # Excellent
 340 | |                 elif metric.value <= metric.threshold_warning * 0.8:
 341 | |                     metric_score = 80.0   # Good
 342 | |                 elif metric.value <= metric.threshold_warning:
 343 | |                     metric_score = 60.0   # Fair
 344 | |                 elif metric.value <= metric.threshold_critical:
 345 | |                     metric_score = 30.0   # Poor
 346 | |                 else:
 347 | |                     metric_score = 0.0    # Critical
 348 | |
 349 | |                 # Apply weighted average
 350 | |                 total_score += metric_score * metric.weight
 351 | |                 total_weight += metric.weight
 352 | |
 353 | |             # Calculate final weighted score
 354 | |             final_score = total_score / total_weight if total_weight > 0 else 0.0
 355 | |
 356 | |             # Store in history
 357 | |             self.health_score_history.append((time.time(), final_score))
 358 | |
 359 | |             return max(0.0, min(100.0, final_score))
 360 | |
 361 | |     def get_health_status(self) -> HealthStatus:
 362 | |         """Get overall health status based on current score."""
 363 | |         score = self.calculate_health_score()
 364 | |
 365 | |         if score >= 80:
 366 | |             return HealthStatus.EXCELLENT
 367 | |         if score >= 60:
 368 | |             return HealthStatus.GOOD
 369 | |         if score >= 40:
 370 | |             return HealthStatus.FAIR
 371 | |         if score >= 20:
 372 | |             return HealthStatus.POOR
 373 | |         return HealthStatus.CRITICAL
 374 | |
 375 | |     def _calculate_api_response_risk(self) -> float:
 376 | |         """Calculate risk from API response time trend."""
 377 | |         if len(self.api_response_times) < 3:
 378 | |             return 0.0
 379 | |
 380 | |         recent_avg = sum(list(self.api_response_times)[-3:]) / 3
 381 | |         if recent_avg > 10.0:
 382 | |             return 0.4
 383 | |         if recent_avg > 8.0:
 384 | |             return 0.3
 385 | |         if recent_avg > 5.0:
 386 | |             return 0.2
 387 | |         return 0.0
 388 | |
 389 | |     def _calculate_error_rate_risk(self) -> float:
 390 | |         """Calculate risk from error rate."""
 391 | |         total_errors = sum(self.error_counts.values())
 392 | |         if total_errors > 15:
 393 | |             return 0.4
 394 | |         if total_errors > 10:
 395 | |             return 0.3
 396 | |         if total_errors > 5:
 397 | |             return 0.2
 398 | |         return 0.0
 399 | |
 400 | |     def _calculate_memory_trend_risk(self) -> float:
 401 | |         """Calculate risk from memory usage trend."""
 402 | |         if len(self.memory_usage_history) < 3:
 403 | |             return 0.0
 404 | |
 405 | |         memory_trend = list(self.memory_usage_history)[-1] - list(self.memory_usage_history)[-3]
 406 | |         if memory_trend > 100:
 407 | |             return 0.2
 408 | |         if memory_trend > 50:
 409 | |             return 0.1
 410 | |         return 0.0
 411 | |
 412 | |     def _calculate_critical_metrics_risk(self) -> float:
 413 | |         """Calculate risk from critical metrics."""
 414 | |         risk = 0.0
 415 | |         for _, metric in self.current_metrics.items():
 416 | |             if metric.value >= metric.threshold_critical:
 417 | |                 risk += 0.15
 418 | |             elif metric.value >= metric.threshold_warning:
 419 | |                 risk += 0.05
 420 | |         return risk
 421 | |
 422 | |     def predict_session_death_risk(self) -> float:
 423 | |         """
 424 | |         Enhanced prediction of session death likelihood in next 10 pages (0.0-1.0).
 425 | |
 426 | |         Returns:
 427 | |             Risk score from 0.0 (very safe) to 1.0 (imminent failure)
 428 | |         """
 429 | |         # Base risk from current health score
 430 | |         health_score = self.calculate_health_score()
 431 | |         health_risk = (100 - health_score) / 100 * 0.5
 432 | |
 433 | |         # Aggregate all risk factors
 434 | |         risk_score = (
 435 | |             health_risk +
 436 | |             self._calculate_api_response_risk() +
 437 | |             self._calculate_error_rate_risk() +
 438 | |             self._calculate_memory_trend_risk() +
 439 | |             self._calculate_critical_metrics_risk()
 440 | |         )
 441 | |
 442 | |         return min(1.0, risk_score)
 443 | |
 444 | |     def get_recommended_actions(self) -> list[str]:
 445 | |         """Get recommended actions based on current health status."""
 446 | |         actions: list[str] = []
 447 | |         health_score = self.calculate_health_score()
 448 | |         risk_score = self.predict_session_death_risk()
 449 | |
 450 | |         if risk_score > 0.8:
 451 | |             actions.append("ðŸš¨ EMERGENCY: Trigger immediate session refresh")
 452 | |             actions.append("ðŸ”„ Restart browser immediately")
 453 | |             actions.append("âš¡ Switch to emergency settings (1 worker, batch 1)")
 454 | |         elif risk_score > 0.6:
 455 | |             actions.append("âš ï¸ CRITICAL: Reduce concurrency to 1 worker")
 456 | |             actions.append("ðŸ“‰ Reduce batch size to 3")
 457 | |             actions.append("ðŸ”„ Schedule session refresh within 5 pages")
 458 | |         elif risk_score > 0.4:
 459 | |             actions.append("âš ï¸ WARNING: Reduce batch size to 5")
 460 | |             actions.append("ðŸ“Š Monitor closely for next 10 pages")
 461 | |             actions.append("ðŸ”„ Consider session refresh within 15 pages")
 462 | |         elif health_score < 60:
 463 | |             actions.append("ðŸ“Š Monitor performance metrics")
 464 | |             actions.append("ðŸ§¹ Consider garbage collection")
 465 | |         else:
 466 | |             actions.append("âœ… System healthy - continue current operations")
 467 | |
 468 | |         return actions
 469 | |
 470 | |     def record_api_response_time(self, response_time: float) -> None:
 471 | |         """Record API response time for monitoring."""
 472 | |         self.api_response_times.append(response_time)
 473 | |
 474 | |         # Update metric
 475 | |         if len(self.api_response_times) >= 5:
 476 | |             avg_response_time = sum(list(self.api_response_times)[-5:]) / 5
 477 | |             self.update_metric("api_response_time", avg_response_time)
 478 | |
 479 | |     def record_error(self, error_type: str) -> None:
 480 | |         """Record an error for monitoring with enhanced rate tracking."""
 481 | |         current_time = time.time()
 482 | |
 483 | |         if error_type not in self.error_counts:
 484 | |             self.error_counts[error_type] = 0
 485 | |         self.error_counts[error_type] += 1
 486 | |
 487 | |         # Track error timestamp for rate analysis
 488 | |         self.error_timestamps.append(current_time)
 489 | |
 490 | |         # Update error rate metric
 491 | |         total_errors = sum(self.error_counts.values())
 492 | |         session_duration_hours = (current_time - self.session_start_time) / 3600
 493 | |         error_rate = total_errors / max(session_duration_hours, 0.1)  # Errors per hour
 494 | |         self.update_metric("error_rate", error_rate)
 495 | |
 496 | |         # Check for early warning conditions
 497 | |         self._check_error_rate_early_warning(current_time)
 498 | |
 499 | |     def _process_error_window_threshold(
 500 | |         self,
 501 | |         window_name: str,
 502 | |         errors_in_window: int,
 503 | |         threshold: int,
 504 | |         current_time: float
 505 | |     ) -> None:
 506 | |         """Process error threshold breach for a specific time window."""
 507 | |         warning_key = f"{window_name}_{threshold}"
 508 | |
 509 | |         # Only send warning once per hour for each threshold
 510 | |         last_warning = self.error_rate_warnings_sent.get(warning_key, 0)
 511 | |         if current_time - last_warning <= 3600:  # 1 hour
 512 | |             return
 513 | |
 514 | |         self.error_rate_warnings_sent[warning_key] = current_time
 515 | |
 516 | |         # Create critical alert
 517 | |         alert = HealthAlert(
 518 | |             level=AlertLevel.CRITICAL,
 519 | |             component="error_rate_monitor",
 520 | |             message=f"ðŸš¨ HIGH ERROR RATE: {errors_in_window} errors in {window_name} (threshold: {threshold})",
 521 | |             metric_name="error_rate_early_warning",
 522 | |             metric_value=errors_in_window,
 523 | |             threshold=threshold,
 524 | |             timestamp=current_time
 525 | |         )
 526 | |
 527 | |         self.alerts.append(alert)
 528 | |         prefix = self._safety_prefix()
 529 | |         logger.critical(f"{prefix}ðŸš¨ CRITICAL ALERT: {alert.message}")
 530 | |
 531 | |         # WORKLOAD-APPROPRIATE: Cascade failure detection with automatic intervention
 532 | |         if window_name == "30-minute" and errors_in_window >= 500:
 533 | |             logger.critical(f"{prefix}ðŸš¨ CASCADE FAILURE DETECTED - EMERGENCY INTERVENTION REQUIRED")
 534 | |             self._trigger_emergency_intervention("CASCADE_FAILURE", errors_in_window, window_name)
 535 | |         elif window_name == "15-minute" and errors_in_window >= 200:
 536 | |             logger.critical(f"{prefix}ðŸš¨ SEVERE ERROR PATTERN DETECTED - Triggering immediate intervention")
 537 | |             self._trigger_immediate_intervention("SEVERE_ERROR_PATTERN", errors_in_window, window_name)
 538 | |         elif window_name == "5-minute" and errors_in_window >= 75:
 539 | |             logger.debug(f"{prefix}âš ï¸ ELEVATED ERROR RATE - Triggering enhanced monitoring")
 540 | |             self._trigger_enhanced_monitoring("ELEVATED_ERROR_RATE", errors_in_window, window_name)
 541 | |
 542 | |     def _check_error_rate_early_warning(self, current_time: float) -> None:
 543 | |         """
 544 | |         PERFORMANCE-OPTIMIZED error rate monitoring for long sessions.
 545 | |
 546 | |         Uses adaptive monitoring intervals and efficient cleanup to reduce overhead.
 547 | |         """
 548 | |         # Adaptive monitoring interval based on current error rate
 549 | |         monitoring_interval = self._get_adaptive_monitoring_interval(current_time)
 550 | |
 551 | |         # Only check at adaptive intervals to reduce overhead
 552 | |         if current_time - self.last_error_rate_check < monitoring_interval:
 553 | |             return
 554 | |
 555 | |         self.last_error_rate_check = current_time
 556 | |
 557 | |         # PERFORMANCE: Efficient cleanup with batched operations
 558 | |         self._perform_efficient_cleanup(current_time)
 559 | |
 560 | |         # Check different time windows for early warning - WORKLOAD-APPROPRIATE for 724 pages
 561 | |         time_windows = [
 562 | |             (1800, 500, "30-minute"),  # 500 errors in 30 minutes (cascade failure)
 563 | |             (900, 200, "15-minute"),   # 200 errors in 15 minutes (severe issues)
 564 | |             (300, 75, "5-minute"),     # 75 errors in 5 minutes (moderate issues)
 565 | |             (60, 15, "1-minute"),      # 15 errors in 1 minute (immediate issues)
 566 | |         ]
 567 | |
 568 | |         for window_seconds, threshold, window_name in time_windows:
 569 | |             window_start = current_time - window_seconds
 570 | |             errors_in_window = sum(1 for ts in self.error_timestamps if ts >= window_start)
 571 | |
 572 | |             if errors_in_window >= threshold:
 573 | |                 self._process_error_window_threshold(window_name, errors_in_window, threshold, current_time)
 574 | |
 575 | |     def get_error_rate_statistics(self) -> dict[str, Any]:
 576 | |         """
 577 | |         Get comprehensive error rate statistics for monitoring and analysis.
 578 | |
 579 | |         Returns:
 580 | |             Dict containing error rate statistics and recommendations
 581 | |         """
 582 | |         current_time = time.time()
 583 | |
 584 | |         # Calculate error rates for different time windows
 585 | |         time_windows = [
 586 | |             (60, "1-minute"),
 587 | |             (300, "5-minute"),
 588 | |             (900, "15-minute"),
 589 | |             (1800, "30-minute"),
 590 | |             (3600, "1-hour"),
 591 | |             (7200, "2-hour")
 592 | |         ]
 593 | |
 594 | |         error_rates = {}
 595 | |         for window_seconds, window_name in time_windows:
 596 | |             window_start = current_time - window_seconds
 597 | |             errors_in_window = sum(1 for ts in self.error_timestamps if ts >= window_start)
 598 | |             error_rates[window_name] = {
 599 | |                 "count": errors_in_window,
 600 | |                 "rate_per_minute": errors_in_window / (window_seconds / 60),
 601 | |                 "window_seconds": window_seconds
 602 | |             }
 603 | |
 604 | |         # Determine risk level - WORKLOAD-APPROPRIATE for 724-page processing
 605 | |         thirty_min_errors = error_rates["30-minute"]["count"]
 606 | |         fifteen_min_errors = error_rates["15-minute"]["count"]
 607 | |         five_min_errors = error_rates["5-minute"]["count"]
 608 | |
 609 | |         if thirty_min_errors >= 500:
 610 | |             risk_level = "CRITICAL"
 611 | |             recommendation = "EMERGENCY_SHUTDOWN"
 612 | |         elif fifteen_min_errors >= 200:
 613 | |             risk_level = "HIGH"
 614 | |             recommendation = "IMMEDIATE_INTERVENTION"
 615 | |         elif five_min_errors >= 75:
 616 | |             risk_level = "MODERATE"
 617 | |             recommendation = "MONITOR_CLOSELY"
 618 | |         elif five_min_errors >= 25:
 619 | |             risk_level = "ELEVATED"
 620 | |             recommendation = "INCREASED_MONITORING"
 621 | |         else:
 622 | |             risk_level = "LOW"
 623 | |             recommendation = "CONTINUE_NORMAL"
 624 | |
 625 | |         return {
 626 | |             "timestamp": current_time,
 627 | |             "error_rates": error_rates,
 628 | |             "total_session_errors": sum(self.error_counts.values()),
 629 | |             "session_duration_minutes": (current_time - self.session_start_time) / 60,
 630 | |             "risk_level": risk_level,
 631 | |             "recommendation": recommendation,
 632 | |             "error_types": dict(self.error_counts),
 633 | |             "recent_alerts": [alert for alert in self.alerts if current_time - alert.timestamp < 3600]
 634 | |         }
 635 | |
 636 | |     def _trigger_emergency_intervention(self, pattern_type: str, error_count: int, window: str) -> None:
 637 | |         """Trigger emergency intervention for cascade failures."""
 638 | |         try:
 639 | |             prefix = self._safety_prefix()
 640 | |             logger.critical(f"{prefix}ðŸš¨ EMERGENCY INTERVENTION TRIGGERED: {pattern_type}")
 641 | |             logger.critical(f"{prefix}   Pattern: {error_count} errors in {window}")
 642 | |             logger.critical(f"{prefix}   Action: Setting emergency halt flag")
 643 | |
 644 | |             # Set emergency halt flag that can be checked by main processing loops
 645 | |             self._emergency_halt_requested = True
 646 | |             self._emergency_halt_reason = f"{pattern_type}: {error_count} errors in {window}"
 647 | |             self._emergency_halt_timestamp = time.time()
 648 | |
 649 | |             # Create critical alert
 650 | |             alert = HealthAlert(
 651 | |                 level=AlertLevel.CRITICAL,
 652 | |                 component="emergency_intervention",
 653 | |                 message=f"ðŸš¨ EMERGENCY HALT: {pattern_type} - {error_count} errors in {window}",
 654 | |                 metric_name="emergency_intervention",
 655 | |                 metric_value=error_count,
 656 | |                 threshold=500 if window == "30-minute" else 200,
 657 | |                 timestamp=time.time()
 658 | |             )
 659 | |             self.alerts.append(alert)
 660 | |
 661 | |             logger.critical(f"{self._safety_prefix()}ðŸš¨ EMERGENCY INTERVENTION COMPLETE - Processing should halt immediately")
 662 | |
 663 | |         except Exception as e:
 664 | |             logger.error(f"Failed to trigger emergency intervention: {e}")
 665 | |
 666 | |     def _trigger_immediate_intervention(self, pattern_type: str, error_count: int, window: str) -> None:
 667 | |         """Trigger immediate intervention for severe error patterns."""
 668 | |         try:
 669 | |             prefix = self._safety_prefix()
 670 | |             logger.critical(f"{prefix}âš ï¸ IMMEDIATE INTERVENTION TRIGGERED: {pattern_type}")
 671 | |             logger.critical(f"{prefix}   Pattern: {error_count} errors in {window}")
 672 | |             logger.critical(f"{prefix}   Action: Setting immediate halt flag and triggering recovery")
 673 | |
 674 | |             # Set immediate intervention flag
 675 | |             self._immediate_intervention_requested = True
 676 | |             self._immediate_intervention_reason = f"{pattern_type}: {error_count} errors in {window}"
 677 | |             self._immediate_intervention_timestamp = time.time()
 678 | |
 679 | |             # Create critical alert
 680 | |             alert = HealthAlert(
 681 | |                 level=AlertLevel.CRITICAL,
 682 | |                 component="immediate_intervention",
 683 | |                 message=f"âš ï¸ IMMEDIATE INTERVENTION: {pattern_type} - {error_count} errors in {window}",
 684 | |                 metric_name="immediate_intervention",
 685 | |                 metric_value=error_count,
 686 | |                 threshold=200 if window == "15-minute" else 75,
 687 | |                 timestamp=time.time()
 688 | |             )
 689 | |             self.alerts.append(alert)
 690 | |
 691 | |             logger.critical(f"{self._safety_prefix()}âš ï¸ IMMEDIATE INTERVENTION COMPLETE - Consider halting or recovery")
 692 | |
 693 | |         except Exception as e:
 694 | |             logger.error(f"Failed to trigger immediate intervention: {e}")
 695 | |
 696 | |     def _trigger_enhanced_monitoring(self, pattern_type: str, error_count: int, window: str) -> None:
 697 | |         """Trigger enhanced monitoring for elevated error rates."""
 698 | |         try:
 699 | |             prefix = self._safety_prefix()
 700 | |             logger.debug(f"{prefix}ðŸ“Š ENHANCED MONITORING TRIGGERED: {pattern_type}")
 701 | |             logger.debug(f"{prefix}   Pattern: {error_count} errors in {window}")
 702 | |             logger.debug(f"{prefix}   Action: Increasing monitoring frequency")
 703 | |
 704 | |             # Set enhanced monitoring flag
 705 | |             self._enhanced_monitoring_active = True
 706 | |             self._enhanced_monitoring_reason = f"{pattern_type}: {error_count} errors in {window}"
 707 | |             self._enhanced_monitoring_timestamp = time.time()
 708 | |
 709 | |             # Reduce monitoring interval for enhanced monitoring
 710 | |             self.last_error_rate_check = time.time() - 25  # Check again in 5 seconds instead of 30
 711 | |
 712 | |             # Create warning alert
 713 | |             alert = HealthAlert(
 714 | |                 level=AlertLevel.WARNING,
 715 | |                 component="enhanced_monitoring",
 716 | |                 message=f"ðŸ“Š ENHANCED MONITORING: {pattern_type} - {error_count} errors in {window}",
 717 | |                 metric_name="enhanced_monitoring",
 718 | |                 metric_value=error_count,
 719 | |                 threshold=75,
 720 | |                 timestamp=time.time()
 721 | |             )
 722 | |             self.alerts.append(alert)
 723 | |
 724 | |             logger.debug(f"{self._safety_prefix()}ðŸ“Š ENHANCED MONITORING ACTIVE - Increased error rate surveillance")
 725 | |
 726 | |         except Exception as e:
 727 | |             logger.error(f"Failed to trigger enhanced monitoring: {e}")
 728 | |
 729 | |     def should_emergency_halt(self) -> bool:
 730 | |         """Check if emergency halt has been requested."""
 731 | |         return self._emergency_halt_requested
 732 | |
 733 | |     def should_immediate_intervention(self) -> bool:
 734 | |         """Check if immediate intervention has been requested."""
 735 | |         return self._immediate_intervention_requested
 736 | |
 737 | |     def is_enhanced_monitoring_active(self) -> bool:
 738 | |         """Check if enhanced monitoring is active."""
 739 | |         return self._enhanced_monitoring_active
 740 | |
 741 | |     def get_intervention_status(self) -> dict[str, Any]:
 742 | |         """Get current intervention status."""
 743 | |         return {
 744 | |             "emergency_halt": {
 745 | |                 "requested": self._emergency_halt_requested,
 746 | |                 "reason": self._emergency_halt_reason,
 747 | |                 "timestamp": self._emergency_halt_timestamp
 748 | |             },
 749 | |             "immediate_intervention": {
 750 | |                 "requested": self._immediate_intervention_requested,
 751 | |                 "reason": self._immediate_intervention_reason,
 752 | |                 "timestamp": self._immediate_intervention_timestamp
 753 | |             },
 754 | |             "enhanced_monitoring": {
 755 | |                 "active": self._enhanced_monitoring_active,
 756 | |                 "reason": self._enhanced_monitoring_reason,
 757 | |                 "timestamp": self._enhanced_monitoring_timestamp
 758 | |             }
 759 | |         }
 760 | |
 761 | |     def reset_intervention_flags(self) -> None:
 762 | |         """Reset intervention flags (use with caution)."""
 763 | |         logger.debug("ðŸ”„ Resetting intervention flags")
 764 | |         self._emergency_halt_requested = False
 765 | |         self._emergency_halt_reason = ""
 766 | |         self._emergency_halt_timestamp = 0.0
 767 | |         self._immediate_intervention_requested = False
 768 | |         self._immediate_intervention_reason = ""
 769 | |         self._immediate_intervention_timestamp = 0.0
 770 | |         self._enhanced_monitoring_active = False
 771 | |         self._enhanced_monitoring_reason = ""
 772 | |         self._enhanced_monitoring_timestamp = 0.0
 773 | |
 774 | |     def _get_adaptive_monitoring_interval(self, current_time: float) -> float:
 775 | |         """Get adaptive monitoring interval based on current system state."""
 776 | |         try:
 777 | |             # Base interval
 778 | |             interval = self._monitoring_interval
 779 | |
 780 | |             # If enhanced monitoring is active, check more frequently
 781 | |             if self._enhanced_monitoring_active:
 782 | |                 interval = 5.0  # Check every 5 seconds during enhanced monitoring
 783 | |             else:
 784 | |                 # Adaptive interval based on recent error rate
 785 | |                 recent_errors = sum(1 for ts in self.error_timestamps if current_time - ts < 300)  # Last 5 minutes
 786 | |
 787 | |                 if recent_errors >= 50:
 788 | |                     interval = 10.0  # High error rate - check every 10 seconds
 789 | |                 elif recent_errors >= 20:
 790 | |                     interval = 20.0  # Moderate error rate - check every 20 seconds
 791 | |                 elif recent_errors >= 5:
 792 | |                     interval = 30.0  # Low error rate - normal interval
 793 | |                 else:
 794 | |                     interval = 60.0  # Very low error rate - check every minute
 795 | |
 796 | |             return interval
 797 | |
 798 | |         except Exception as e:
 799 | |             logger.debug(f"Error calculating adaptive interval: {e}")
 800 | |             return self._monitoring_interval
 801 | |
 802 | |     def _perform_efficient_cleanup(self, current_time: float) -> None:
 803 | |         """Perform efficient cleanup of old data to reduce memory usage."""
 804 | |         try:
 805 | |             # Only perform cleanup every 5 minutes to reduce overhead
 806 | |             if current_time - self._last_cleanup_time < self._cleanup_interval:
 807 | |                 return
 808 | |
 809 | |             self._last_cleanup_time = current_time
 810 | |
 811 | |             # Clean old error timestamps (older than 2 hours for long sessions)
 812 | |             cutoff_time = current_time - 7200  # 2 hours
 813 | |
 814 | |             # PERFORMANCE: Batch cleanup instead of one-by-one
 815 | |             cleanup_count = 0
 816 | |             while self.error_timestamps and self.error_timestamps[0] < cutoff_time:
 817 | |                 self.error_timestamps.popleft()
 818 | |                 cleanup_count += 1
 819 | |
 820 | |                 # Prevent excessive cleanup in one operation
 821 | |                 if cleanup_count > 1000:
 822 | |                     break
 823 | |
 824 | |             # Clean old warning timestamps
 825 | |             warning_cutoff = current_time - 3600  # 1 hour
 826 | |             old_warnings = [key for key, timestamp in self.error_rate_warnings_sent.items()
 827 | |                           if timestamp < warning_cutoff]
 828 | |             for key in old_warnings:
 829 | |                 del self.error_rate_warnings_sent[key]
 830 | |
 831 | |             # Clean old alerts (keep only last 4 hours)
 832 | |             alert_cutoff = current_time - 14400  # 4 hours
 833 | |             self.alerts = [alert for alert in self.alerts if alert.timestamp >= alert_cutoff]
 834 | |
 835 | |             if cleanup_count > 0:
 836 | |                 logger.debug(f"Cleaned up {cleanup_count} old error timestamps and {len(old_warnings)} old warnings")
 837 | |
 838 | |         except Exception as e:
 839 | |             logger.debug(f"Error during efficient cleanup: {e}")
 840 | |
 841 | |     def optimize_for_long_session(self) -> None:
 842 | |         """Optimize monitoring settings for long-running sessions (20+ hours)."""
 843 | |         try:
 844 | |             logger.info("ðŸ”§ Optimizing health monitoring for long session")
 845 | |
 846 | |             # Increase monitoring intervals to reduce overhead
 847 | |             self._monitoring_interval = 60.0  # Check every minute instead of 30 seconds
 848 | |             self._cleanup_interval = 600.0    # Clean up every 10 minutes instead of 5
 849 | |
 850 | |             # Increase deque sizes for longer data retention
 851 | |             if self.error_timestamps.maxlen is None or self.error_timestamps.maxlen < 3000:
 852 | |                 # Create new deque with larger size and copy existing data
 853 | |                 old_timestamps = list(self.error_timestamps)
 854 | |                 self.error_timestamps = deque(old_timestamps, maxlen=3000)
 855 | |
 856 | |             # Optimize metrics history for longer sessions
 857 | |             for name in self.metrics_history:
 858 | |                 current_maxlen = self.metrics_history[name].maxlen
 859 | |                 if current_maxlen is None or current_maxlen < 200:
 860 | |                     old_history = list(self.metrics_history[name])
 861 | |                     self.metrics_history[name] = deque(old_history, maxlen=200)
 862 | |
 863 | |             logger.info("âœ… Health monitoring optimized for long session")
 864 | |
 865 | |         except Exception as e:
 866 | |             logger.debug(f"Failed to optimize for long session: {e}")
 867 | |
 868 | |     def get_performance_stats(self) -> dict[str, Any]:
 869 | |         """Get performance statistics for monitoring overhead analysis."""
 870 | |         try:
 871 | |             current_time = time.time()
 872 | |             session_duration = (current_time - self.session_start_time) / 3600  # Hours
 873 | |
 874 | |             return {
 875 | |                 "session_duration_hours": session_duration,
 876 | |                 "error_timestamps_count": len(self.error_timestamps),
 877 | |                 "error_timestamps_max": self.error_timestamps.maxlen,
 878 | |                 "alerts_count": len(self.alerts),
 879 | |                 "warnings_sent_count": len(self.error_rate_warnings_sent),
 880 | |                 "current_monitoring_interval": self._monitoring_interval,
 881 | |                 "adaptive_monitoring_enabled": self._adaptive_interval,
 882 | |                 "last_cleanup_age_minutes": (current_time - self._last_cleanup_time) / 60,
 883 | |                 "memory_efficiency": {
 884 | |                     "error_timestamps_usage": f"{len(self.error_timestamps)}/{self.error_timestamps.maxlen}",
 885 | |                     "metrics_history_total": sum(len(hist) for hist in self.metrics_history.values()),
 886 | |                     "alerts_retention_hours": 4,
 887 | |                     "warnings_retention_hours": 1
 888 | |                 }
 889 | |             }
 890 | |
 891 | |         except Exception as e:
 892 | |             logger.debug(f"Error getting performance stats: {e}")
 893 | |             return {"error": str(e)}
 894 | |
 895 | |     def record_page_processing_time(self, processing_time: float) -> None:
 896 | |         """Record page processing time."""
 897 | |         self.page_processing_times.append(processing_time)
 898 | |
 899 | |     def update_system_metrics(self) -> None:
 900 | |         """Update system-level metrics (CPU, memory, etc.)."""
 901 | |         try:
 902 | |             # Memory usage
 903 | |             process = psutil.Process()
 904 | |             memory_mb = process.memory_info().rss / 1024 / 1024
 905 | |             self.memory_usage_history.append(memory_mb)
 906 | |             self.update_metric("memory_usage_mb", memory_mb)
 907 | |
 908 | |             # CPU usage
 909 | |             cpu_percent = psutil.cpu_percent(interval=0.1)
 910 | |             self.update_metric("cpu_usage_percent", cpu_percent)
 911 | |
 912 | |             # Disk usage
 913 | |             disk_usage = psutil.disk_usage('/').percent
 914 | |             self.update_metric("disk_usage_percent", disk_usage)
 915 | |
 916 | |         except Exception as e:
 917 | |             logger.debug(f"Error updating system metrics: {e}")
 918 | |
 919 | |     def _update_browser_health_metrics(self, monitor: Any) -> None:
 920 | |         """Update browser health metrics from monitor."""
 921 | |         if not (hasattr(monitor, 'get') or isinstance(monitor, dict)):
 922 | |             return
 923 | |
 924 | |         monitor_dict = cast(dict[str, Any], monitor)
 925 | |
 926 | |         # Browser age
 927 | |         browser_start_time = monitor_dict.get('browser_start_time', time.time())
 928 | |         if browser_start_time:
 929 | |             browser_age_minutes = (time.time() - browser_start_time) / 60
 930 | |             self.update_metric("browser_age_minutes", browser_age_minutes)
 931 | |
 932 | |         # Pages since refresh
 933 | |         pages_since_refresh = monitor_dict.get('pages_since_refresh', 0)
 934 | |         if pages_since_refresh is not None:
 935 | |             self.update_metric("pages_since_refresh", pages_since_refresh)
 936 | |
 937 | |     def _update_session_health_metrics(self, session_monitor: Any) -> None:
 938 | |         """Update session health metrics from monitor."""
 939 | |         if not (hasattr(session_monitor, 'get') or isinstance(session_monitor, dict)):
 940 | |             return
 941 | |
 942 | |         session_monitor_dict = cast(dict[str, Any], session_monitor)
 943 | |         session_start = session_monitor_dict.get('session_start_time', time.time())
 944 | |         if session_start:
 945 | |             session_age_minutes = (time.time() - session_start) / 60
 946 | |             self.update_metric("session_age_minutes", session_age_minutes)
 947 | |
 948 | |     def update_session_metrics(self, session_manager: Any = None) -> None:
 949 | |         """Update session-specific metrics with enhanced error handling."""
 950 | |         try:
 951 | |             # Session age
 952 | |             session_age_minutes = (time.time() - self.session_start_time) / 60
 953 | |             self.update_metric("session_age_minutes", session_age_minutes)
 954 | |
 955 | |             if session_manager:
 956 | |                 # Handle browser health monitor
 957 | |                 if hasattr(session_manager, 'browser_health_monitor'):
 958 | |                     try:
 959 | |                         self._update_browser_health_metrics(session_manager.browser_health_monitor)
 960 | |                     except Exception as browser_exc:
 961 | |                         logger.debug(f"Browser health monitor update failed: {browser_exc}")
 962 | |
 963 | |                 # Handle session health monitor
 964 | |                 if hasattr(session_manager, 'session_health_monitor'):
 965 | |                     try:
 966 | |                         self._update_session_health_metrics(session_manager.session_health_monitor)
 967 | |                     except Exception as session_exc:
 968 | |                         logger.debug(f"Session health monitor update failed: {session_exc}")
 969 | |
 970 | |         except Exception as e:
 971 | |             logger.debug(f"Error updating session metrics: {e}")
 972 | |
 973 | |     def get_health_dashboard(self) -> dict[str, Any]:
 974 | |         """Get comprehensive health dashboard data."""
 975 | |         health_score = self.calculate_health_score()
 976 | |         health_status = self.get_health_status()
 977 | |         risk_score = self.predict_session_death_risk()
 978 | |
 979 | |         return {
 980 | |             "timestamp": time.time(),
 981 | |             "health_score": health_score,
 982 | |             "health_status": health_status.value,
 983 | |             "risk_score": risk_score,
 984 | |             "risk_level": self._get_risk_level(risk_score),
 985 | |             "metrics": {name: {
 986 | |                 "value": metric.value,
 987 | |                 "status": metric.status.value,
 988 | |                 "threshold_warning": metric.threshold_warning,
 989 | |                 "threshold_critical": metric.threshold_critical
 990 | |             } for name, metric in self.current_metrics.items()},
 991 | |             "recent_alerts": [
 992 | |                 {
 993 | |                     "level": alert.level.value,
 994 | |                     "component": alert.component,
 995 | |                     "message": alert.message,
 996 | |                     "timestamp": alert.timestamp
 997 | |                 } for alert in self.alerts[-5:]  # Last 5 alerts
 998 | |             ],
 999 | |             "recommended_actions": self.get_recommended_actions(),
1000 | |             "performance_summary": {
1001 | |                 "avg_api_response_time": sum(self.api_response_times) / len(self.api_response_times) if self.api_response_times elseâ€¦
1002 | |                 "total_errors": sum(self.error_counts.values()),
1003 | |                 "avg_page_processing_time": sum(self.page_processing_times) / len(self.page_processing_times) if self.page_processinâ€¦
1004 | |                 "current_memory_mb": self.memory_usage_history[-1] if self.memory_usage_history else 0
1005 | |             }
1006 | |         }
1007 | |
1008 | |     @staticmethod
1009 | |     def _get_risk_level(risk_score: float) -> str:
1010 | |         """Convert risk score to human-readable level."""
1011 | |         if risk_score > 0.8:
1012 | |             return "EMERGENCY"
1013 | |         if risk_score > 0.6:
1014 | |             return "CRITICAL"
1015 | |         if risk_score > 0.4:
1016 | |             return "WARNING"
1017 | |         if risk_score > 0.2:
1018 | |             return "CAUTION"
1019 | |         return "SAFE"
1020 | |
1021 | |     def log_health_summary(self) -> None:
1022 | |         """Log a comprehensive health summary."""
1023 | |         dashboard = self.get_health_dashboard()
1024 | |
1025 | |         logger.info("ðŸ“Š HEALTH SUMMARY:")
1026 | |         logger.info(f"   Score: {dashboard['health_score']:.1f}/100 ({dashboard['health_status'].upper()})")
1027 | |         logger.info(f"   Risk: {dashboard['risk_score']:.2f} ({dashboard['risk_level']})")
1028 | |         logger.info(f"   API: {dashboard['performance_summary']['avg_api_response_time']:.1f}s avg")
1029 | |         logger.info(f"   Memory: {dashboard['performance_summary']['current_memory_mb']:.1f}MB")
1030 | |         logger.info(f"   Errors: {dashboard['performance_summary']['total_errors']}")
1031 | |
1032 | |         if dashboard['recommended_actions']:
1033 | |             logger.info(f"   Actions: {dashboard['recommended_actions'][0]}")
1034 | |
1035 | |     # === SESSION STATE PERSISTENCE ===
1036 | |
1037 | |     def create_session_checkpoint(self, checkpoint_name: Optional[str] = None) -> str:
1038 | |         """Create a checkpoint of the current session state for recovery."""
1039 | |         try:
1040 | |             if checkpoint_name is None:
1041 | |                 checkpoint_name = f"checkpoint_{int(time.time())}"
1042 | |
1043 | |             # Create checkpoint directory
1044 | |             checkpoint_dir = Path("Cache/session_checkpoints")
1045 | |             checkpoint_dir.mkdir(parents=True, exist_ok=True)
1046 | |
1047 | |             # Prepare session state data
1048 | |             session_state = {
1049 | |                 "timestamp": time.time(),
1050 | |                 "checkpoint_name": checkpoint_name,
1051 | |                 "session_start_time": self.session_start_time,
1052 | |                 "health_score_history": list(self.health_score_history),
1053 | |                 "current_metrics": {
1054 | |                     name: {
1055 | |                         "value": metric.value,
1056 | |                         "status": metric.status.value,
1057 | |                         "threshold_warning": metric.threshold_warning,
1058 | |                         "threshold_critical": metric.threshold_critical,
1059 | |                         "timestamp": metric.timestamp
1060 | |                     } for name, metric in self.current_metrics.items()
1061 | |                 },
1062 | |                 "alerts": [
1063 | |                     {
1064 | |                         "level": alert.level.value,
1065 | |                         "component": alert.component,
1066 | |                         "message": alert.message,
1067 | |                         "metric_name": alert.metric_name,
1068 | |                         "metric_value": alert.metric_value,
1069 | |                         "threshold": alert.threshold,
1070 | |                         "timestamp": alert.timestamp
1071 | |                     } for alert in self.alerts
1072 | |                 ],
1073 | |                 "error_timestamps": list(self.error_timestamps),
1074 | |                 "error_counts": dict(self.error_counts),
1075 | |                 "api_response_times": list(self.api_response_times),
1076 | |                 "page_processing_times": list(self.page_processing_times),
1077 | |                 "memory_usage_history": list(self.memory_usage_history),
1078 | |                 "intervention_state": {
1079 | |                     "emergency_halt_requested": self._emergency_halt_requested,
1080 | |                     "immediate_intervention_requested": self._immediate_intervention_requested,
1081 | |                     "enhanced_monitoring_active": self._enhanced_monitoring_active,
1082 | |                     "monitoring_interval": self._monitoring_interval,
1083 | |                     "last_cleanup_time": self._last_cleanup_time
1084 | |                 },
1085 | |                 "performance_stats": self.get_performance_stats()
1086 | |             }
1087 | |
1088 | |             # Save checkpoint to file
1089 | |             checkpoint_file = checkpoint_dir / f"{checkpoint_name}.json"
1090 | |             with checkpoint_file.open('w', encoding='utf-8') as f:
1091 | |                 json.dump(session_state, f, indent=2, default=str)
1092 | |
1093 | |             logger.info(f"ðŸ“ Session checkpoint created: {checkpoint_name}")
1094 | |             return str(checkpoint_file)
1095 | |
1096 | |         except Exception as e:
1097 | |             logger.error(f"Failed to create session checkpoint: {e}")
1098 | |             return ""
1099 | |
1100 | |     def _restore_metrics_from_state(self, session_state: dict[str, Any]) -> None:
1101 | |         """Restore current metrics from session state."""
1102 | |         if "current_metrics" not in session_state:
1103 | |             return
1104 | |
1105 | |         for name, metric_data in session_state["current_metrics"].items():
1106 | |             metric = HealthMetric(
1107 | |                 name=name,
1108 | |                 value=metric_data["value"],
1109 | |                 threshold_warning=metric_data["threshold_warning"],
1110 | |                 threshold_critical=metric_data["threshold_critical"],
1111 | |                 timestamp=metric_data.get("timestamp", time.time())
1112 | |             )
1113 | |             self.current_metrics[name] = metric
1114 | |
1115 | |     def _restore_alerts_from_state(self, session_state: dict[str, Any]) -> None:
1116 | |         """Restore alerts from session state."""
1117 | |         if "alerts" not in session_state:
1118 | |             return
1119 | |
1120 | |         self.alerts = []
1121 | |         for alert_data in session_state["alerts"]:
1122 | |             level = AlertLevel(alert_data["level"])
1123 | |             alert = HealthAlert(
1124 | |                 level=level,
1125 | |                 component=alert_data["component"],
1126 | |                 message=alert_data["message"],
1127 | |                 metric_name=alert_data["metric_name"],
1128 | |                 metric_value=alert_data["metric_value"],
1129 | |                 threshold=alert_data["threshold"],
1130 | |                 timestamp=alert_data["timestamp"]
1131 | |             )
1132 | |             self.alerts.append(alert)
1133 | |
1134 | |     def _restore_error_data_from_state(self, session_state: dict[str, Any]) -> None:
1135 | |         """Restore error tracking data from session state."""
1136 | |         if "error_timestamps" in session_state:
1137 | |             self.error_timestamps = deque(session_state["error_timestamps"], maxlen=self.error_timestamps.maxlen)
1138 | |
1139 | |         if "error_counts" in session_state:
1140 | |             self.error_counts.update(session_state["error_counts"])
1141 | |
1142 | |     def _restore_performance_data_from_state(self, session_state: dict[str, Any]) -> None:
1143 | |         """Restore performance tracking data from session state."""
1144 | |         if "api_response_times" in session_state:
1145 | |             self.api_response_times = deque(session_state["api_response_times"], maxlen=self.api_response_times.maxlen)
1146 | |
1147 | |         if "page_processing_times" in session_state:
1148 | |             self.page_processing_times = deque(session_state["page_processing_times"], maxlen=self.page_processing_times.maxlen)
1149 | |
1150 | |         if "memory_usage_history" in session_state:
1151 | |             self.memory_usage_history = deque(session_state["memory_usage_history"], maxlen=self.memory_usage_history.maxlen)
1152 | |
1153 | |     def _restore_intervention_state_from_state(self, session_state: dict[str, Any]) -> None:
1154 | |         """Restore intervention state from session state."""
1155 | |         if "intervention_state" not in session_state:
1156 | |             return
1157 | |
1158 | |         intervention = session_state["intervention_state"]
1159 | |         self._emergency_halt_requested = intervention.get("emergency_halt_requested", False)
1160 | |         self._immediate_intervention_requested = intervention.get("immediate_intervention_requested", False)
1161 | |         self._enhanced_monitoring_active = intervention.get("enhanced_monitoring_active", False)
1162 | |         self._monitoring_interval = intervention.get("monitoring_interval", 30.0)
1163 | |         self._last_cleanup_time = intervention.get("last_cleanup_time", time.time())
1164 | |
1165 | |     def restore_from_checkpoint(self, checkpoint_path: str) -> bool:
1166 | |         """Restore session state from a checkpoint file."""
1167 | |         try:
1168 | |             checkpoint_file = Path(checkpoint_path)
1169 | |             if not checkpoint_file.exists():
1170 | |                 logger.error(f"Checkpoint file not found: {checkpoint_path}")
1171 | |                 return False
1172 | |
1173 | |             # Load checkpoint data
1174 | |             with checkpoint_file.open(encoding='utf-8') as f:
1175 | |                 session_state = json.load(f)
1176 | |
1177 | |             # Restore session state
1178 | |             self.session_start_time = session_state.get("session_start_time", time.time())
1179 | |
1180 | |             # Restore health score history
1181 | |             if "health_score_history" in session_state:
1182 | |                 self.health_score_history = deque(session_state["health_score_history"], maxlen=100)
1183 | |
1184 | |             # Restore all state components
1185 | |             self._restore_metrics_from_state(session_state)
1186 | |             self._restore_alerts_from_state(session_state)
1187 | |             self._restore_error_data_from_state(session_state)
1188 | |             self._restore_performance_data_from_state(session_state)
1189 | |             self._restore_intervention_state_from_state(session_state)
1190 | |
1191 | |             logger.info(f"ðŸ”„ Session state restored from checkpoint: {checkpoint_file.name}")
1192 | |             return True
1193 | |
1194 | |         except Exception as e:
1195 | |             logger.error(f"Failed to restore from checkpoint: {e}")
1196 | |             return False
1197 | |
1198 | |     def auto_checkpoint(self, interval_minutes: int = 30) -> None:
1199 | |         """Automatically create checkpoints at regular intervals."""
1200 | |         try:
1201 | |             current_time = time.time()
1202 | |             if not hasattr(self, '_last_checkpoint_time'):
1203 | |                 self._last_checkpoint_time = current_time
1204 | |
1205 | |             # Check if it's time for a checkpoint
1206 | |             if current_time - self._last_checkpoint_time >= (interval_minutes * 60):
1207 | |                 checkpoint_name = f"auto_checkpoint_{int(current_time)}"
1208 | |                 self.create_session_checkpoint(checkpoint_name)
1209 | |                 self._last_checkpoint_time = current_time
1210 | |
1211 | |                 # Clean up old auto checkpoints (keep only last 5)
1212 | |                 self._cleanup_old_checkpoints()
1213 | |
1214 | |         except Exception as e:
1215 | |             logger.debug(f"Auto checkpoint failed: {e}")
1216 | |
1217 | |     @staticmethod
1218 | |     def _cleanup_old_checkpoints(keep_count: int = 5) -> None:
1219 | |         """Clean up old checkpoint files, keeping only the most recent ones."""
1220 | |         try:
1221 | |             checkpoint_dir = Path("Cache/session_checkpoints")
1222 | |             if not checkpoint_dir.exists():
1223 | |                 return
1224 | |
1225 | |             # Get all auto checkpoint files
1226 | |             auto_checkpoints = list(checkpoint_dir.glob("auto_checkpoint_*.json"))
1227 | |
1228 | |             # Sort by modification time (newest first)
1229 | |             auto_checkpoints.sort(key=lambda x: x.stat().st_mtime, reverse=True)
1230 | |
1231 | |             # Remove old checkpoints
1232 | |             for checkpoint in auto_checkpoints[keep_count:]:
1233 | |                 try:
1234 | |                     checkpoint.unlink()
1235 | |                     logger.debug(f"Removed old checkpoint: {checkpoint.name}")
1236 | |                 except Exception as e:
1237 | |                     logger.debug(f"Failed to remove checkpoint {checkpoint.name}: {e}")
1238 | |
1239 | |         except Exception as e:
1240 | |             logger.debug(f"Checkpoint cleanup failed: {e}")
1241 | |         else:
1242 | |             try:
1243 | |                 from cache_retention import auto_enforce_retention
1244 | |
1245 | |                 auto_enforce_retention("session_checkpoints")
1246 | |             except Exception as retention_error:
1247 | |                 logger.debug("Retention sweep for session checkpoints skipped: %s", retention_error)
1248 | |
1249 | |     @staticmethod
1250 | |     def list_available_checkpoints() -> list[dict[str, Any]]:
1251 | |         """List all available checkpoint files with metadata."""
1252 | |         try:
1253 | |             checkpoint_dir = Path("Cache/session_checkpoints")
1254 | |             if not checkpoint_dir.exists():
1255 | |                 return []
1256 | |
1257 | |             checkpoints: list[dict[str, Any]] = []
1258 | |             for checkpoint_file in checkpoint_dir.glob("*.json"):
1259 | |                 try:
1260 | |                     # Get file metadata
1261 | |                     stat = checkpoint_file.stat()
1262 | |
1263 | |                     # Try to read checkpoint metadata
1264 | |                     with checkpoint_file.open(encoding='utf-8') as f:
1265 | |                         data = json.load(f)
1266 | |
1267 | |                     checkpoints.append({
1268 | |                         "name": checkpoint_file.stem,
1269 | |                         "file_path": str(checkpoint_file),
1270 | |                         "created_time": data.get("timestamp", stat.st_mtime),
1271 | |                         "file_size_kb": stat.st_size / 1024,
1272 | |                         "session_start_time": data.get("session_start_time"),
1273 | |                         "health_score": data.get("performance_stats", {}).get("health_score", "N/A"),
1274 | |                         "total_errors": data.get("performance_stats", {}).get("total_errors", 0)
1275 | |                     })
1276 | |
1277 | |                 except Exception as e:
1278 | |                     logger.debug(f"Failed to read checkpoint metadata for {checkpoint_file.name}: {e}")
1279 | |
1280 | |             # Sort by creation time (newest first)
1281 | |             checkpoints.sort(key=lambda x: x["created_time"], reverse=True)
1282 | |             return checkpoints
1283 | |
1284 | |         except Exception as e:
1285 | |             logger.error(f"Failed to list checkpoints: {e}")
1286 | |             return []
1287 | |
1288 | |     def persist_session_state_to_disk(self, session_data: Optional[dict[str, Any]] = None) -> str:
1289 | |         """Persist current session state to disk for crash recovery."""
1290 | |         try:
1291 | |             # Create persistent state directory
1292 | |             state_dir = Path("Cache/session_state")
1293 | |             state_dir.mkdir(parents=True, exist_ok=True)
1294 | |
1295 | |             # Prepare session state data
1296 | |             if session_data is None:
1297 | |                 session_data = {}
1298 | |
1299 | |             # Add health monitoring state
1300 | |             session_data.update({
1301 | |                 "health_monitor": {
1302 | |                     "session_start_time": self.session_start_time,
1303 | |                     "current_metrics": {name: metric.value for name, metric in self.current_metrics.items()},
1304 | |                     "error_count": len(self.error_timestamps),
1305 | |                     "alert_count": len(self.alerts),
1306 | |                     "health_score": self.calculate_health_score(),
1307 | |                     "intervention_state": {
1308 | |                         "emergency_halt": self._emergency_halt_requested,
1309 | |                         "immediate_intervention": self._immediate_intervention_requested,
1310 | |                         "enhanced_monitoring": self._enhanced_monitoring_active
1311 | |                     }
1312 | |                 },
1313 | |                 "timestamp": time.time()
1314 | |             })
1315 | |
1316 | |             # Save to persistent state file
1317 | |             state_file = state_dir / "current_session.json"
1318 | |             with state_file.open('w', encoding='utf-8') as f:
1319 | |                 json.dump(session_data, f, indent=2, default=str)
1320 | |
1321 | |             logger.debug(f"Session state persisted to disk: {state_file}")
1322 | |
1323 | |             try:
1324 | |                 from cache_retention import auto_enforce_retention
1325 | |
1326 | |                 auto_enforce_retention("session_state")
1327 | |             except Exception as retention_error:
1328 | |                 logger.debug("Retention sweep for session state skipped: %s", retention_error)
1329 | |
1330 | |             return str(state_file)
1331 | |
1332 | |         except Exception as e:
1333 | |             logger.error(f"Failed to persist session state: {e}")
1334 | |             return ""
1335 | |
1336 | |     def recover_session_state_from_disk(self) -> Optional[dict[str, Any]]:
1337 | |         """Recover session state from disk after a crash."""
1338 | |         try:
1339 | |             state_file = Path("Cache/session_state/current_session.json")
1340 | |             if not state_file.exists():
1341 | |                 logger.info("No previous session state found")
1342 | |                 return None
1343 | |
1344 | |             # Load session state
1345 | |             with state_file.open(encoding='utf-8') as f:
1346 | |                 session_data = json.load(f)
1347 | |
1348 | |             # Check if state is recent (within last 24 hours)
1349 | |             state_age = time.time() - session_data.get("timestamp", 0)
1350 | |             if state_age > 86400:  # 24 hours
1351 | |                 logger.info("Previous session state is too old, ignoring")
1352 | |                 return None
1353 | |
1354 | |             # Restore health monitoring state if available
1355 | |             if "health_monitor" in session_data:
1356 | |                 health_data = session_data["health_monitor"]
1357 | |
1358 | |                 # Restore basic state
1359 | |                 if "session_start_time" in health_data:
1360 | |                     self.session_start_time = health_data["session_start_time"]
1361 | |
1362 | |                 # Restore intervention state
1363 | |                 if "intervention_state" in health_data:
1364 | |                     intervention = health_data["intervention_state"]
1365 | |                     self._emergency_halt_requested = intervention.get("emergency_halt", False)
1366 | |                     self._immediate_intervention_requested = intervention.get("immediate_intervention", False)
1367 | |                     self._enhanced_monitoring_active = intervention.get("enhanced_monitoring", False)
1368 | |
1369 | |             logger.info(f"ðŸ”„ Session state recovered from disk (age: {state_age / 60:.1f} minutes)")
1370 | |             return session_data
1371 | |
1372 | |         except Exception as e:
1373 | |             logger.error(f"Failed to recover session state: {e}")
1374 | |             return None
     | |_______________________^
     |

Found 6 errors.
