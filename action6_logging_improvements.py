#!/usr/bin/env python3

"""
Action 6 Logging Improvements

Optimized logging configuration specifically for Action 6 to reduce clutter
while maintaining useful debug information and adding performance metrics.
"""

import logging
from typing import Dict, Any, Optional
from datetime import datetime
import time
from contextlib import contextmanager


class Action6Logger:
    """Specialized logger for Action 6 with performance tracking and reduced verbosity."""
    
    def __init__(self, base_logger: logging.Logger):
        self.base_logger = base_logger
        self.start_time = time.time()
        self.api_call_count = 0
        self.rate_limit_time = 0.0
        self.batch_metrics = {}
        self.current_batch = None
    
    @contextmanager
    def batch_context(self, batch_num: int, match_count: int):
        """Context manager for batch processing with automatic metrics."""
        self.current_batch = batch_num
        batch_start = time.time()
        
        # Reduced verbosity: Only INFO level for batch start
        self.base_logger.info(f"ðŸ”„ Processing batch {batch_num} ({match_count} matches)")
        
        try:
            yield self
        finally:
            batch_duration = time.time() - batch_start
            self.batch_metrics[batch_num] = {
                'duration': batch_duration,
                'match_count': match_count,
                'matches_per_second': match_count / batch_duration if batch_duration > 0 else 0
            }
            
            # Performance summary (INFO level)
            mps = self.batch_metrics[batch_num]['matches_per_second']
            self.base_logger.info(f"âœ… Batch {batch_num} complete: {match_count} matches in {batch_duration:.1f}s ({mps:.2f} matches/sec)")
    
    def api_call_start(self, api_name: str, url: str) -> float:
        """Log API call start with reduced verbosity."""
        self.api_call_count += 1
        start_time = time.time()
        
        # Only DEBUG for individual API calls, not INFO
        self.base_logger.debug(f"ðŸŒ {api_name}: {url}")
        return start_time
    
    def api_call_end(self, api_name: str, start_time: float, status_code: int, rate_limit_wait: float = 0):
        """Log API call completion with metrics."""
        duration = time.time() - start_time
        self.rate_limit_time += rate_limit_wait
        
        # Only log if unusual (non-200) or slow (>5s)
        if status_code != 200 or duration > 5.0:
            self.base_logger.warning(f"âš ï¸  {api_name}: {status_code} in {duration:.2f}s")
        elif rate_limit_wait > 0:
            self.base_logger.debug(f"â³ {api_name}: {status_code} (+{rate_limit_wait:.1f}s wait)")
    
    def rate_limit_summary(self, total_wait_time: float):
        """Log rate limiting summary instead of every individual wait."""
        if total_wait_time > 10:  # Only log if significant
            percent_waiting = (total_wait_time / (time.time() - self.start_time)) * 100
            self.base_logger.info(f"â³ Rate limiting: {total_wait_time:.1f}s total wait ({percent_waiting:.1f}% of time)")
    
    def performance_summary(self):
        """Log overall performance summary."""
        total_time = time.time() - self.start_time
        total_matches = sum(m['match_count'] for m in self.batch_metrics.values())
        
        if total_matches > 0:
            avg_matches_per_sec = total_matches / total_time
            rate_limit_percent = (self.rate_limit_time / total_time) * 100
            
            self.base_logger.info(f"""
ðŸ“Š Action 6 Performance Summary:
   â€¢ Total matches processed: {total_matches}
   â€¢ Total time: {total_time:.1f}s
   â€¢ Average throughput: {avg_matches_per_sec:.2f} matches/sec
   â€¢ API calls made: {self.api_call_count}
   â€¢ Time spent rate limiting: {self.rate_limit_time:.1f}s ({rate_limit_percent:.1f}%)
   â€¢ Batches completed: {len(self.batch_metrics)}""")


def optimize_action6_logging():
    """Apply optimized logging configuration for Action 6."""
    
    # Reduce verbosity of specific loggers that are too chatty
    verbose_loggers = [
        'utils',      # Rate limiting logs
        'action6_',   # Individual match processing
        'api_mana',   # API management details
        'database',   # Database session details
    ]
    
    for logger_name in verbose_loggers:
        logger = logging.getLogger(logger_name)
        # Set to INFO instead of DEBUG to reduce chatter
        if logger.level == logging.DEBUG:
            logger.setLevel(logging.INFO)
    
    # Keep important loggers at DEBUG for troubleshooting
    important_loggers = [
        'session_',   # Session management issues
        'browser_',   # Browser/navigation problems
        'main',       # Main application flow
    ]
    
    for logger_name in important_loggers:
        logger = logging.getLogger(logger_name)
        logger.setLevel(logging.DEBUG)


# Suggested rate limiting improvements
OPTIMIZED_RATE_LIMITS = {
    'base_delay': 1.5,          # Reduced from 2.0s
    'max_delay': 8.0,           # Reduced from 12.0s  
    'backoff_factor': 3.0,      # Reduced from 4.0
    'bucket_size': 3.0,         # Increased from 2.0
    'refill_rate': 0.7,         # Increased from 0.5
    'parallel_workers': 3,      # Increased from 2
}


# Suggested API optimization strategies
API_OPTIMIZATION_STRATEGIES = {
    'batch_in_tree_checks': True,      # Already implemented
    'cache_profile_details': True,     # Cache profile data across matches
    'conditional_probability': True,   # Skip probability API for low-priority matches
    'smart_retry_logic': True,         # Exponential backoff with jitter
    'connection_pooling': True,        # Reuse HTTP connections
    'compress_requests': True,         # Enable gzip compression
}


def get_performance_recommendations() -> Dict[str, str]:
    """Get specific recommendations for Action 6 performance improvements."""
    return {
        'rate_limiting': f"Reduce base delay from 2.0s to {OPTIMIZED_RATE_LIMITS['base_delay']}s",
        'parallelization': f"Increase workers from 2 to {OPTIMIZED_RATE_LIMITS['parallel_workers']}",
        'caching': "Implement profile details caching for repeated profile IDs",
        'api_efficiency': "Skip Match Probability API for matches with low relevance scores",
        'logging': "Switch verbose loggers from DEBUG to INFO level",
        'connection_reuse': "Enable HTTP connection pooling and keep-alive",
        'error_handling': "Add circuit breaker pattern for failing API endpoints"
    }


if __name__ == "__main__":
    print("ðŸ”§ Action 6 Performance Optimization Recommendations:")
    print("=" * 60)
    
    recommendations = get_performance_recommendations()
    for category, recommendation in recommendations.items():
        print(f"â€¢ {category.title()}: {recommendation}")
    
    print("\nðŸ“Š Estimated Performance Improvements:")
    print("â€¢ Rate limiting optimization: 20-25% faster")
    print("â€¢ Increased parallelization: 30-40% faster") 
    print("â€¢ Profile caching: 15-20% faster")
    print("â€¢ Logging optimization: 5-10% faster")
    print("â€¢ Combined estimated improvement: 70-95% faster")
