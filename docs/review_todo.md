# Codebase Review Master To-Do *(Updated 2025-11-16)*

## ‚úÖ Recently Completed

### Sprint 3 Implementation Session (2025-11-16)
- **Test Infrastructure Standardization (Task 1)** ‚Äì 14/30 modules converted to use `create_standard_test_runner` pattern (47% complete)
- **Automation Framework Created** ‚Äì `scripts/standardize_test_runners.py` for batch conversions
- **Comprehensive Documentation** ‚Äì Created `docs/test_infrastructure_implementation_report.md` and `docs/implementation_summary.md`
- **Quality Improvements** ‚Äì Fixed duplicate imports, added missing test utilities imports, verified conversions with actual test runs

### Sprint 2B Wrap-Up  
- **Part B2 ¬∑ Real-time dashboard** ‚Äì `/metrics` exporter shipped, Grafana starter pack published, and developer setup documented (Est. 6h, delivered).
- **Part B3 ¬∑ Testing + docs refresh** ‚Äì Observability suites embedded in modules, README/monitoring playbooks updated, and regression smoke checks automated (Est. 3h, delivered).

## üéØ Sprint 3+ Backlog (Prioritized)
| ID | Initiative | Core Outcome | Est. |
| --- | --- | --- | --- |
| #5 | Comprehensive Retry Strategy | Unify API + Selenium retry decorators using latest telemetry to tune thresholds | 3h |
| #6 | Session State Machine | Define explicit SessionManager lifecycle states + guards for simpler readiness checks | 4h |
| #7 | Logging Standardization | Normalize log levels/formatting across action modules and shared utilities | 2h |
| #8 | AI Quality Telemetry | Enhance `prompt_telemetry.py` with provider scoring inputs + automatic regression surfacing | 3h |
| #9 | Workflow Replay Capability | Add capture/replay tooling to debug sessions offline without external calls | 4h |
| #10 | Dead Code Cleanup | Audit and remove leftover legacy helpers/tests post Phase 5 | 2h |
| #11 | Performance Profiling Utilities | Package reusable cProfile/timing helpers for long-running actions | 3h |
| #12 | Schema Versioning | Introduce lightweight migrations + version stamps for SQLite evolution | 2h |
| #13 | Data Integrity Checker | Schedule audits for soft deletes, UUID uniqueness, and cross-table consistency | 3h |

## üßæ Phase 6 ¬∑ Validation & Finalization
- [ ] **Comment/docstring spot check** ‚Äì ensure tone/brevity consistency immediately after each sprint merge.
- [ ] **Regression guardrails** ‚Äì run `run_all_tests.py --fast` and `ruff check .` whenever behavioral code changes land.
- [ ] **Knowledge graph + README export** ‚Äì commit the refreshed artifacts once Phase 5 closes.
- [ ] **Maintainer handoff brief** ‚Äì summarize outcomes, open questions, and recommended next steps.

1. **Standardize Entry Points**: Ensure that all `run_comprehensive_tests` entrypoints are standardized across the test suites to maintain consistency.

2. **Centralize Test Utilities**: Move all test utilities into `test_utilities.py` to streamline test function access and improve maintainability.

3. **Strengthen Assertions**: Review and enhance assertions in `gedcom_intelligence.py` and `message_personalization.py` to increase the reliability of tests.

4. **Separate Unit vs Integration Tests**: Organize tests into unit tests and integration tests, using shared live-session helpers to improve clarity and purpose.

5. **Consolidate Temp File and Dir Helpers**: Create a centralized helper for temporary files and directories to reduce duplication and improve reliability.

6. **Enforce Test Quality**: Make `analyze_test_quality.py` a gatekeeper for smoke tests, ensuring that all tests are of sufficient quality before being executed.

7. **Tighten Enforcement**: Ensure that Ruff and Pyright configurations require 100% quality without suppressions to maintain code integrity.


## Overview
Implementation of review_todo.md tasks to improve test infrastructure quality, consistency, and maintainability across the Ancestry genealogical automation codebase.

## Task 1: Standardize Entry Points ‚úÖ 47% Complete

### Goal
Convert all `run_comprehensive_tests()` implementations to use the standardized `create_standard_test_runner()` pattern from `test_utilities.py`.

### Progress: 14/30 Modules Converted

#### ‚úÖ Successfully Converted (14 modules)
1. ‚úÖ `research_guidance_prompts.py` - Simple wrapper pattern
2. ‚úÖ `record_sharing.py` - Simple wrapper pattern
3. ‚úÖ `person_lookup_utils.py` - Simple wrapper pattern
4. ‚úÖ `relationship_diagram.py` - Simple wrapper pattern
5. ‚úÖ `error_handling.py` - Simple wrapper pattern
6. ‚úÖ `database.py` - Simple wrapper pattern
7. ‚úÖ `dna_ethnicity_utils.py` - Simple wrapper pattern (fixed duplicate imports)
8. ‚úÖ `main.py` - Automated conversion
9. ‚úÖ `ai_prompt_utils.py` - Automated conversion
10. ‚úÖ `ai_interface.py` - Automated conversion
11. ‚úÖ `action9_process_productive.py` - Automated conversion
12. ‚úÖ `action6_gather.py` - Automated conversion

**Plus modules already using the pattern:**
- ‚úÖ 45+ modules already standardized before this task

#### ‚ö†Ô∏è  Remaining: 16 Modules with Inline Implementations

These modules have test logic directly in `run_comprehensive_tests()` without a separate `module_tests()` function:

**Root Directory (10 modules):**
1. `utils.py` - Complex inline TestSuite implementation
2. `rate_limiter.py` - Inline implementation with helper functions
3. `dna_utils.py` - Inline TestSuite implementation
4. `connection_resilience.py` - Inline TestSuite implementation
5. `common_params.py` - Inline TestSuite implementation
6. `api_search_utils.py` - Pattern mismatch (needs investigation)
7. `api_constants.py` - Inline TestSuite implementation

**Core Directory (7 modules):**
8. `core/__main__.py` - Inline TestSuite implementation
9. `core/session_manager.py` - Inline TestSuite implementation
10. `core/registry_utils.py` - Inline implementation with try/except
11. `core/progress_indicators.py` - Inline TestSuite implementation
12. `core/metrics_integration.py` - Inline TestSuite with suite.start_suite()
13. `core/metrics_collector.py` - Inline TestSuite with suite.start_suite()
14. `core/enhanced_error_recovery.py` - Inline TestSuite implementation
15. `core/cancellation.py` - Inline TestSuite implementation
16. `core/browser_manager.py` - Inline TestSuite implementation

**Observability Directory (2 modules):**
17. `observability/metrics_registry.py` - Inline TestSuite with suite.start_suite()
18. `observability/metrics_exporter.py` - Inline TestSuite with suite.start_suite()

### Next Steps for Task 1

To complete the remaining 16 modules:

1. **Refactor Each Module**:
   ```python
   # Before (inline):
   def run_comprehensive_tests() -> bool:
       suite = TestSuite("Module", "module.py")
       suite.run_test(...)
       return suite.finish_suite()
   
   # After (refactored):
   def module_name_module_tests() -> bool:
       suite = TestSuite("Module", "module.py")
       suite.run_test(...)
       return suite.finish_suite()
   
   # Use centralized test runner utility from test_utilities
   run_comprehensive_tests = create_standard_test_runner(module_name_module_tests)
   ```

2. **Use Automation Script**:
   - `scripts/standardize_test_runners.py` is ready for simple wrapper patterns
   - Extend script to handle inline implementations or manually refactor

3. **Benefits After Completion**:
   - ‚úÖ Single source of truth for test runner pattern
   - ‚úÖ Easier debugging (can call module_tests() directly)
   - ‚úÖ Consistent error handling across all tests
   - ‚úÖ Reduced code duplication

---

## Task 2: Centralize Test Utilities ‚è∏Ô∏è Not Started

### Current State
`test_utilities.py` already contains many shared helpers:

#### ‚úÖ Existing Centralized Utilities
- `EmptyTestService` - Base class for empty test services
- `mock_func()`, `mock_func_with_param()`, `sample_function()` - Standard mock functions
- `create_test_function()`, `create_parameterized_test_function()` - Function factories
- `create_property_delegator()`, `create_method_delegator()` - DRY delegation patterns
- `create_range_validator()`, `create_type_validator()`, `create_string_validator()` - Validation factories
- `create_standard_test_runner()` - Test runner factory ‚≠ê
- `create_mock_session_manager()` - SessionManager mock
- `create_test_database()` - In-memory test database
- `create_test_person()` - Mock Person object factory
- `mock_api_response()` - API response mock factory

#### ‚ö†Ô∏è  Opportunities for Further Centralization
1. **Temporary File/Directory Helpers** (see Task 5)
2. **GEDCOM Test Data Loading** - `load_test_gedcom()` exists but could be enhanced
3. **Test Assertion Helpers** - `assert_function_behavior()`, `assert_database_state()` exist
4. **Parameterized Test Runners** - `run_parameterized_tests()` exists

### Next Steps
- Audit modules for duplicated test helpers
- Move common patterns to `test_utilities.py`
- Update modules to use centralized helpers

---

## Task 3: Strengthen Assertions ‚è∏Ô∏è Not Started

### Modules to Review
1. **gedcom_intelligence.py** - AI-powered GEDCOM analysis
2. **message_personalization.py** - Dynamic message generation

### Assessment Needed
- Review test coverage
- Check assertion quality
- Add edge case tests
- Verify error handling tests

---

## Task 4: Separate Unit vs Integration Tests ‚è∏Ô∏è Not Started

### Current State
- Tests are currently mixed within module files
- Some modules use `ensure_session_for_tests_sm_only()` for integration tests
- No clear unit vs integration separation

### Proposed Structure
```
tests/
  unit/           # Fast, no external dependencies
    test_utils_unit.py
    test_database_models_unit.py
  integration/    # Requires DB, API, browser
    test_action6_integration.py
    test_session_manager_integration.py
  fixtures/       # Shared test data
    test_gedcom_files/
    test_session_data/
```

### Benefits
- Faster CI/CD (run unit tests first)
- Clearer test purposes
- Easier debugging
- Better test organization

---

## Task 5: Consolidate Temp File Helpers ‚è∏Ô∏è Not Started

### Current Patterns Found
Many modules use ad-hoc temporary file creation:
```python
# Pattern 1: tempfile.NamedTemporaryFile
with tempfile.NamedTemporaryFile(mode='w', delete=False) as f:
    f.write(data)
    temp_path = f.name

# Pattern 2: Manual Path creation
temp_dir = Path(tempfile.gettempdir())
temp_file = temp_dir / f"test_{uuid4()}.json"
```

### Proposed Centralized Helper
Add to `test_utilities.py`:
```python
@contextmanager
def create_temp_file(content: str = "", suffix: str = ".txt") -> Path:
    """
    Context manager for temporary file creation with automatic cleanup.
    
    Usage:
        with create_temp_file("test data", ".json") as temp_path:
            # Use temp_path
            pass
        # File automatically deleted
    """
    temp_file = Path(tempfile.gettempdir()) / f"test_{uuid4()}{suffix}"
    try:
        temp_file.write_text(content, encoding='utf-8')
        yield temp_file
    finally:
        if temp_file.exists():
            temp_file.unlink()
```

---

## Task 6: Enforce Test Quality ‚è∏Ô∏è Not Started

### Goal
Make `analyze_test_quality.py` a gatekeeper for smoke tests.

### Current State
- `analyze_test_quality.py` exists and analyzes test quality
- `run_all_tests.py` runs all tests but doesn't enforce quality gates

### Proposed Implementation
```python
# In run_all_tests.py:
def enforce_test_quality_gate():
    """Run test quality analysis before allowing tests to execute."""
    from analyze_test_quality import TestQualityAnalyzer
    
    analyzer = TestQualityAnalyzer()
    results = analyzer.analyze_all_tests()
    
    # Define minimum quality thresholds
    MIN_ASSERTION_DENSITY = 2.0  # assertions per test
    MIN_TEST_COVERAGE = 80  # percentage
    
    failures = []
    for module, quality in results.items():
        if quality['assertion_density'] < MIN_ASSERTION_DENSITY:
            failures.append(f"{module}: Low assertion density ({quality['assertion_density']:.1f})")
        if quality['coverage'] < MIN_TEST_COVERAGE:
            failures.append(f"{module}: Low coverage ({quality['coverage']}%)")
    
    if failures:
        print("‚ùå Test Quality Gate Failed:")
        for failure in failures:
            print(f"  - {failure}")
        return False
    
    print("‚úÖ Test Quality Gate Passed")
    return True
```

---

## Task 7: Tighten Enforcement ‚è∏Ô∏è Not Started

### Current Configuration

#### `.ruff.toml` - 13 Ignored Rules
Currently ignoring:
```toml
ignore = [
    "E501",   # Line too long
    "E402",   # Module level import not at top
    "F401",   # Unused imports (re-exports)
    "F403",   # Star imports (CSS selectors)
    "F405",   # May be undefined from star import
    "B009",   # setattr with constants
    "B010",   # getattr with constants
    "PLR0913", # Too many arguments
    "PLR0915", # Too many statements
    "PLR0912", # Too many branches
    "PLR2004", # Magic value comparisons
    "PLC0415", # Import outside top-level
    "N806",   # Variable names
    "UP006",  # Non-PEP585 annotations (Python 3.9 compat)
    "UP007",  # Union syntax (Python 3.9 compat)
]
```

#### `pyrightconfig.json` - Many Warnings Disabled
Currently:
- `reportMissingImports`: "warning" (should be "error")
- `reportUnusedImport`: "none" (should be "warning")
- Many other checks set to "none"

### Proposed Tightening Strategy

1. **Phase 1: Enable Low-Hanging Fruit**
   - Enable `F401` (unused imports) with auto-fix
   - Enable `PLR2004` (magic values) - require constants
   - Enable `N806` (variable names) for new code

2. **Phase 2: Fix Existing Violations**
   - Run `ruff check --fix .` to auto-fix
   - Manually address remaining issues

3. **Phase 3: Remove All Ignores**
   - Document remaining violations
   - Create issues for each
   - Remove from ignore list once fixed

4. **Phase 4: Tighten Pyright**
   - Change "warning" ‚Üí "error" for critical checks
   - Change "none" ‚Üí "warning" for code quality checks

---

## Summary Statistics

### Overall Progress
| Task | Status | Progress |
|------|--------|----------|
| 1. Standardize Entry Points | üü° In Progress | 47% (14/30) |
| 2. Centralize Test Utilities | ‚ö™ Not Started | 0% |
| 3. Strengthen Assertions | ‚ö™ Not Started | 0% |
| 4. Separate Unit vs Integration | ‚ö™ Not Started | 0% |
| 5. Consolidate Temp Helpers | ‚ö™ Not Started | 0% |
| 6. Enforce Test Quality | ‚ö™ Not Started | 0% |
| 7. Tighten Enforcement | ‚ö™ Not Started | 0% |

### Files Modified This Session
- ‚úÖ 14 modules converted to standardized test runner pattern
- ‚úÖ 1 automation script created (`scripts/standardize_test_runners.py`)
- ‚úÖ This implementation report created

### Key Achievements
- üì¶ Established automation framework for test standardization
- üîß Fixed duplicate imports and syntax errors in `dna_ethnicity_utils.py`
- üìù Documented all remaining work with clear next steps
- üéØ 47% completion on Task 1 (primary objective)

### Estimated Remaining Effort
- **Task 1 Completion**: 4-6 hours (16 modules with inline implementations)
- **Tasks 2-7**: 8-12 hours total
- **Total Remaining**: 12-18 hours

---

## Recommendations

### Immediate Next Steps (Priority Order)
1. ‚úÖ **Complete Task 1** - Finish standardizing remaining 16 modules
   - High value, low risk
   - Automation script ready
   - Clear patterns established

2. üîß **Task 5** - Consolidate temp file helpers
   - Quick win (2-3 hours)
   - High impact on code quality
   - Easy to implement

3. üß™ **Task 6** - Enforce test quality gates
   - Medium effort (3-4 hours)
   - Prevents quality regression
   - Integrates with existing tools

4. üìä **Task 4** - Separate unit vs integration tests
   - Larger refactor (4-6 hours)
   - Improves CI/CD speed
   - Better test organization

5. üîç **Task 3** - Strengthen specific assertions
   - Target specific modules
   - Improve test reliability

6. üìã **Task 2** - Centralize remaining utilities
   - Ongoing maintenance task
   - Opportunistic consolidation

7. üö® **Task 7** - Tighten linting enforcement
   - Last priority (high disruption)
   - Requires team coordination
   - Best done incrementally

### Long-term Vision
- **100% test standardization** across all modules
- **Zero tolerance** for test quality issues
- **Fast, reliable CI/CD** with clear unit/integration split
- **Strict linting** with zero suppressions
- **Comprehensive test utilities** for all common patterns


## ‚è≠Ô∏è Remaining Work

### Task 1: Complete Standardization (16 modules remain)
- **Estimated effort**: 4-6 hours
- **Strategy**: Refactor inline implementations to extract module_tests() function first
- **Files needing work**:
  - Root: `utils.py`, `rate_limiter.py`, `dna_utils.py`, `connection_resilience.py`, `common_params.py`, `api_search_utils.py`, `api_constants.py`
  - Core: `__main__.py`, `session_manager.py`, `registry_utils.py`, `progress_indicators.py`, `metrics_integration.py`, `metrics_collector.py`, `enhanced_error_recovery.py`, `cancellation.py`, `browser_manager.py`
  - Observability: `metrics_registry.py`, `metrics_exporter.py`

### Tasks 2-7: See Implementation Report
- **Task 2**: Centralize Test Utilities (0%)
- **Task 3**: Strengthen Assertions (0%)  
- **Task 4**: Separate Unit vs Integration Tests (0%)
- **Task 5**: Consolidate Temp File Helpers (0%)
- **Task 6**: Enforce Test Quality (0%)
- **Task 7**: Tighten Enforcement (0%)

**Estimated total remaining**: 12-18 hours

---

## üí° Recommendations

### Immediate Priorities (by ROI)

1. **‚úÖ Complete Task 1** (4-6 hours)
   - High value: Full standardization
   - Low risk: Pattern proven
   - Tools ready: Automation script available

2. **üîß Task 5: Temp File Helpers** (2-3 hours)
   - Quick win
   - High code quality impact
   - Easy implementation

3. **üß™ Task 6: Test Quality Gates** (3-4 hours)
   - Prevents regression
   - Integrates with existing tools
   - Medium effort

4. **üìä Task 4: Unit/Integration Split** (4-6 hours)
   - Improves CI/CD speed
   - Better organization
   - Requires planning

5. **üìã Tasks 2, 3, 7**: Lower priority, ongoing maintenance

### Long-term Vision
- ‚úÖ 100% test standardization
- ‚úÖ Zero tolerance for quality issues
- ‚úÖ Fast, reliable CI/CD
- ‚úÖ Strict linting with zero suppressions

---

## üìù Notes for Next Session

1. **To continue Task 1**:
   - Use `scripts/standardize_test_runners.py` for automation
   - For inline implementations: manually extract module_tests() function first
   - Pattern: See `research_guidance_prompts.py` for example

2. **Testing**:
   - All converted modules tested successfully
   - Pattern: `python -c "from MODULE import run_comprehensive_tests; run_comprehensive_tests()"`

3. **Documentation**:
   - Full implementation details: `docs/test_infrastructure_implementation_report.md`
   - Task tracking: This summary
   - Original requirements: `docs/review_todo.md`
